#### vol. 17 no. 4, December, 2012

# Analysing the effects of individual characteristics and self-efficacy on users' preferences for system features in relevance judgment

#### [Yin-Leng Theng](#authors) and [Sei-Ching Joanna Sin](#authors)  
Division of Information Studies, Wee Kim Wee School of Communication and Information, Nanyang Technological University. 31 Nanyang Link, Singapore 637718

#### Abstract

> **Introduction.** The design of information systems has traditionally focused on algorithmic relevance. While scholars have called for a user-centred perspective on relevance, less is known about what system features are important in supporting subjective relevance judgment of different individuals.  
> **Method.** Drawing from Kuhlthau's information search process and Norman's task completion model, an integrated model conceptualising information seeking on two levels (process and sub-task) were developed. Two hundred and seventy-seven users were surveyed on system features they considered important at various stages of an information seeking task.  
> **Analysis.** Descriptive statistics and exploratory factor analysis were used to group system features. The relationships between system feature preference and individual characteristics were tested using multiple regressions.  
> **Results.** The top features were identified and factor analysis resulted in a seven-factor solution. Except for sex, the multiple regression analyses found statistically significant relationships between individual characteristics such as self-efficacy in information seeking and respondent's system feature preference.  
> **Conclusions.** Information systems design will benefit from understanding users' varying information seeking self-efficacy and their needs for features supporting subjective relevance judgment. With its strong tradition of studying diverse human behaviour, the information behaviour field has much to offer a user-centred and context-aware approach to information system design.

## Introduction

Information behaviour scholars have espoused the importance of user perspective and contextual influences, which contribute to a deeper understanding of the diversity and complexity in information practices ([Case, 2008](#cas08); [Dervin and Nilan 1986](#der86); [Fisher and Julien 2009](#fis09); [Vakkari _et al._ 1997](#vak97); [Wilson 2000](#wil00)). In the design of information systems, on the other hand, a user-centred perspective has yet to gain as strong an appreciation. Traditional information retrieval research has focused mainly on an objective and system-based approach to relevance that has focused on matching documents with query terms. Such a system-centred focus hinders the effective delivery of relevant information to diverse users ([Froehlich 1994](#fro94)).

There is a need for a user-centred perspective on relevance; that is, there is a need to conceptualise relevance as a subjective, individualised mental experience that involves cognitive restructuring ([Borlund 2003](#bor03)). Subjective relevance takes the user's knowledge and information needs into consideration. It is also dynamic: over time, one's view of what is relevant will change as knowledge and exposure to one's knowledge domains broadens. What is considered relevant might also change according to the task at hand and the users' understanding of the task itself. Currently, due to the dearth of studies on subjective relevance, less is known about what information system features are important in supporting the subjective relevance judgment of different individuals.

In light of the above research gap, this study surveyed over 200 users on the system features that they consider important to information seeking and retrieval. It tested whether individual preferences for particular system features are influenced by individual differences (such as sex and information literacy skills, particularly self-efficacy at different stages of the information search process). The findings will help inform the design of information systems that facilitate the individual's subjective relevance judgment. They will also demonstrate the need for a user-centred and context-aware approach to the design of information systems.

## Literature Review

### System-based relevance versus subjective relevance

Traditionally, the design of information retrieval systems has been based on system relevance. This approach focuses on developing algorithms that best match documents to query terms. However, it has been recognised that query terms may not always sufficiently reflect user needs ([Taylor 1962](#tay62)). There are increasing criticisms of the system-based relevance approach because it relies on a priori relevance judgments made by non-users.

User-criteria studies, on the other hand, are based on the idea that relevance judgments should be made by users who are motivated by their own information problem situations. They also highlight that relevance judgments should consider a multitude of factors ([Barry and Schamber 1998](#bar98)). Saracevic ([1996](#sar96); [2007a](#sar07a)) identified five types of relevance: (a) System or algorithmic relevance, which is centred on matching documents with query terms; (b) Topical or ubject relevance, which examines the relationship between the query topic and documents; (c) Cognitive relevance or pertinence, which focuses on users' current knowledge state; (d) Situational relevance or utility, which refers to the usefulness of the retrieved documents to the user's task; (e) Motivational or affective relevance, which reflects the relationship between the documents and the user's intentions, goals and motivations. Cosijn and Ingwersen ([2000](#cos00)) conceptualized affective relevance as influencing all other types of subjective relevance (topical, cognitive, situational and socio-cognitive). Apart from system relevance, which assumes that relevance does not change across contexts or users, the other four types of relevance are recognised as subjective; in other words, as context- and user-dependent ([Kelly 2004](#kel04)). For more discussion on relevance, readers are referred to in-depth reviews such as Borlund ([2003](#bor03)), Cosijn and Ingwersen ([2000](#cos00)), and Saracevic ([1996](#sar96), [2007a](#sar07a), [2007b](#sar07b)).

Many studies have been conducted to identify the criteria (such as depth or scope, currency, specificity) that individuals use to make relevance judgments ([Barry and Schamber 1998](#bar98); [Taylor 1962](#tay62); [Taylor, Cool, Belkin, and Amadio 2007](#tay07); to name a few). Due to the complex nature of information needs and behaviour, researchers have not established what criteria are most important to different users in different situations ([Anderson 2005](#and05)). With the exception of topicality, no consensus has been reached on other relevance judgment criteria ([Anderson 2005](#and05); [Barry and Schamber 1998](#bar98); [Chen and Xu 2005](#che05)).

Beyond studies on relevance judgment criteria, few have ventured forward to study the system features that support users' non-topical relevance judgments. Lee, Theng, and Goh ([2004](#lee04); [2007](#lee07)) conducted qualitative studies to elicit features that can be incorporated into digital library interfaces to aid users' subjective relevance judgment. In a subsequent study, a survey and exploratory factor analysis was conducted to group system features into broader categories ([Lee _et al._ 2006](#lee06)). These studies did not examine how individual differences affect preferences for various system features. This is an area that the current study seeks to address.

### Process of information seeking

The time dimension of information behaviour ([Savolainen 2006](#sav06)), specifically the process of information seeking, is important to the study of relevance. Experiments have shown that through interactions with an information system (e.g., viewing of structured documents), a user's relevance judgment can evolve during a search process ([Kagolovsky and Moehr 2004](#kag04)). In Anderson's ([2005](#and05)) view, the act of retrieving materials from an information system is not a single interaction, but is a complex process of interaction between a user and a system; neither the system nor the user can judge relevance in advance.

Taylor and colleagues ([Taylor _et al._ 2007](#tay07)) showed that students pick different relevance criteria at different stages of their information search (picking, learning, formulating, and writing). Vakkari and Hakala ([2000](#vak00)) found that the top criteria in evaluating the relevance of references changed only slightly over the information search stages. Information content, specifically topicality, remained the most important factors across all stages. Interestingly, the authors found that when the evaluation of full-texts are concerned, there were more changes in relevance criteria across stages. Tang and Solomon ([2001](#tan01)) showed that while topicality remained an important factor across search stages in their laboratory study, participants in their naturalistic study rated topicality as less important in the second stage when full-text articles were evaluated. Nowadays, full texts are increasingly accessible in many online retrieval systems. It is thus timely to continue exploring the relationship between search stages and relevance judgment. We thus hypothesised that design features used for relevance judgment may also vary, and match with the stages of the information seeking process.

The current study focused on academic information seeking. We conceptualised the search process on two levels (see Figure 1). On the higher level, students go through Kuhlthau's information search process of initiation, selection, exploration, formulation, collection, and presentation ([Kuhlthau 1991](#kuh91)). Throughout these six stages, students will engage in many sub-tasks (second-level processes). These sub-tasks may include interaction with information systems to retrieve documents, or seeking advice from faculty members. In this study, the focus is on sub-tasks that involve the use of information retrieval systems.

Norman's task completion model ([1988](#nor88)) provides the basis for the second (sub-task) level of the information-seeking process. Norman's model states that a searcher undergoes seven stages of cognitive actions: goal, intention, planning, execution, perception, interpretation, and evaluation. In this study, the seven-stage model, reduced to five stages by Carroll ([2000](#car00)), is grouped into three phases: 1) Before executing an action: This includes user actions that address (a) formation of goals and intentions; and (b) planning and specifying the action sequence. 2) Executing an action: This includes (a) carrying out the planned action sequence; and (b) perceiving and interpreting the system's response. 3) Evaluation: This includes evaluating the system's effectiveness with respect to the goal and intentions in helping the user to complete his/her goal.

<figure class="centre">![Figure 1\. Enhanced process of information seeking](p536fig1.jpg)

<figcaption>  
Figure 1: Enhanced process of information seeking integrating Kuhlthau's information search process and Norman's simplified model of task completion</figcaption>

</figure>

### Individual differences: self-efficacy in information seeking

Effective information seeking and use relies in part on an individual's information literacy skills. Self-efficacy is a significant factor in many facets of information behaviour [(Case _et al._ 2005](#cas05); [Nahl 2005](#nah05); [Wilson 1999](#wil99)). We hypothesised that individuals with varying self-efficacy and skill levels may require different system features to support their information search. Instead of simply examining overall self-efficacy in information seeking, we are interested in a more detailed differentiation of the various aspects of the information-seeking process. This study draws from the Big 6 model ([Lowe and Eisenberg 2005](#low05)), which includes: (a) task definition; (b) information-seeking strategies; (c) location and access; (d) use of information; (e) synthesis; and (f) evaluation.

With the focus on information searches with an information retrieval system, this study studied these five aspects: (a) task definition/question formulation; (b) information-seeking strategies - identifying potential sources; (c) information seeking strategies - developing search strategies and queries; (d) accessing sources; and (e) evaluation.

### Summary

Relevance research has established the diversity in relevance judgment and the importance of understanding individuals' subjective relevance evaluation. Information behaviour research, on the other hand, has shed light on the dynamic nature of the information-seeking process. It is uncertain, however, what features of the systems are considered by diverse individuals as useful in their relevance evaluation across the different information-seeking stages. This exploratory study is a step toward addressing this research gap.

## The study

### Research questions

This study examines the preferred system features that support the individual's subjective relevance judgment. Specifically, the research questions are:

#### Research question 1: system features

*   Research question 1.1\. What system features do users perceive as important to their relevance judgment in their academic information search process?
*   Research question 1.2\. What are the major system-feature categories users perceive as important to their relevance judgment and how are these categories ranked?

#### Research question 2: Individual characteristics and rating of design features

*   Research question 2.1\. What are the bivariate relationships among individual characteristics and perceived importance of the system features?
*   Research question 2.2\. To what extent do the following contribute to the perceived importance of system feature categories in respondent's academic information search process: (a) sex; (b) years of online experience; (c) perceived competence as an online searcher; (d) frequency of Internet use; (e) self-efficacy in question formulation; (f) self-efficacy in identification of sources; (g) self-efficacy in developing search strategies; (h) self-efficacy in accessing information sources; and (i) self-efficacy in evaluating information?

### Methods

#### Design of survey instrument

The study instrument was developed through a small-scale focus-group session. Four participants, two search experts and two novices, were recruited to elicit the desirable and expected information system features that support subjective relevance judgment. Scholars have underscored the importance of contextual factors, such as tasks, to individual behaviour. We thus specified a task for the participants, which was the completion of a literature review for a term paper. This task is selected to emulate the research paper assignment used by Kuhlthau in her studies on the search process ([Kuhlthau 1991](#kuh91)). Such a task would involve the use of different information systems and resources. In this study, we focused on the sub-tasks in which users interact with academic journal databases and digital libraries. Future studies may examine the types of features and services that aid subjective relevance judgment across different information sources. At the start of the session, participants were briefed on what they were expected to do. They were then given twenty minutes to explore three information retrieval systems: (a) Emerald Fulltext; (b) Library and Information Science Abstracts; and (c) ACM Digital Library. In the course of using the systems, participants were asked to take note of features that helped them complete their task and features that could be improved, as well as features that should have been included. At the end of the twenty minutes, the participants came together to brainstorm features that they thought would help them identify relevant documents. During this brainstorming session, the participants were encouraged to generate as many features as possible, but refrain from commenting on the features generated. After the brainstorming session, the participants were asked which of the generated design features was most important to them.

#### Measures

The discussion section generated a list of twenty-six features that were considered useful for supporting the three stages of the sub-task level information search process (i.e., before executing an action, executing an action, and evaluation; Figure 1) and subjective relevance judgment (see Table 1). Survey participants were asked to rate the importance of each feature using a five-point Likert scale, from 1 ('not important') to 5 ('very important'). Participants also evaluated their efficacy in executing different actions (such as question formation, identifying potential sources) during the information seeking process. This was rated on a five-point Likert scale. Other demographics data and user characteristics, such as perceived competence in online searching (i.e., novice, intermediate, or expert searchers), were also collected.

<table class="center"><caption>  
Table 1: List of system features</caption>

<tbody>

<tr>

<th>Item no.</th>

<th>Stage 1: Before executing the search task</th>

</tr>

<tr>

<td>1_1</td>

<td>Display search options in order of the most commonly used options (e.g., title, author, year of publication)</td>

</tr>

<tr>

<td>1_2</td>

<td>Provide more search options (e.g., search by title, author, abstract) for better query formulation</td>

</tr>

<tr>

<td>1_3</td>

<td>Allow the use of simple, intuitive commands such as AND, OR, NOT in basic search</td>

</tr>

<tr>

<td>1_4</td>

<td>Provide a command line search option in the advanced search</td>

</tr>

<tr>

<td>1_5</td>

<td>Allow you to change from one subject area to another when searching</td>

</tr>

<tr>

<td>1_6</td>

<td>Provide search tutorials and search examples to help query formulation (e.g., online help or system suggested examples)</td>

</tr>

<tr>

<th>Item no.</th>

<th>Stage 2: Executing the search task</th>

</tr>

<tr>

<td>2_1</td>

<td>Have search results list formatted and displayed in a simple, uncluttered interface would help identify relevant documents more easily</td>

</tr>

<tr>

<td>2_2</td>

<td>In the search results list, the system categorises documents based on document types, so that results would be grouped by journals, conference proceedings, etc.</td>

</tr>

<tr>

<td>2_3</td>

<td>Rank the items in the search results list by percentage of relevance</td>

</tr>

<tr>

<td>2_4</td>

<td>Allow you to review the search history of past queries submitted and the corresponding search results list</td>

</tr>

<tr>

<td>2_5</td>

<td>Search results list to provide a recommendation of documents and related topics based on the query submitted</td>

</tr>

<tr>

<td>2_6</td>

<td>Highlight the query words in the search results list</td>

</tr>

<tr>

<td>2_7</td>

<td>Provide each document's abstract in the search results list</td>

</tr>

<tr>

<td>2_8</td>

<td>Show year of publication to indicate how current the document for each item in the search result list</td>

</tr>

<tr>

<td>2_9</td>

<td>Provide documentation to inform how search results are ranked</td>

</tr>

<tr>

<td>2_10</td>

<td>Recommend search tips based on your query (e.g., the system suggests alternative query terms)</td>

</tr>

<tr>

<th>Item no.</th>

<th>Stage 3: Evaluation</th>

</tr>

<tr>

<td>3_1</td>

<td>Include the email address(es) of the author(s) of the retrieved document(s)</td>

</tr>

<tr>

<td>3_2</td>

<td>Indicate how many times a document in the search results has been cited or used by others</td>

</tr>

<tr>

<td>3_3</td>

<td>Highlight search query words in the document text retrieved from the search</td>

</tr>

<tr>

<td>3_4</td>

<td>Provide a feature to "find more documents like this one" for each search result shown</td>

</tr>

<tr>

<td>3_5</td>

<td>Provide an indication to show that you have already reviewed, opened, or downloaded this document previously</td>

</tr>

<tr>

<td>3_6</td>

<td>Allow you to view the table of contents in the source document if its full-text is not available</td>

</tr>

<tr>

<td>3_7</td>

<td>As part of the search results, the system also provides a URL to the actual journal for general information (e.g., publisher's information, accessibility rights) about that document source</td>

</tr>

<tr>

<td>3_8</td>

<td>Specify the pages in which the query words appear in the document's contents and provide direct links to the pages</td>

</tr>

<tr>

<td>3_9</td>

<td>Provide URL links to full-text documents that are referenced in the current document or search results</td>

</tr>

<tr>

<td>3_10</td>

<td>Provide access to a subject specific forum, where you can seek others' views on the documents retrieved or any other related matter</td>

</tr>

</tbody>

</table>

#### Analysis methods

Research question 1.1 was examined through descriptive statistics of the twenty-six system features. Research question 1.2 concerns the grouping of system features. Factor analysis, a technique for identifying the underlying structure among variables, was selected for this purpose. Research question 2 focused on the roles of individual characteristics. First, for Research question 2.1, relationships among the nine individual characteristics (such as sex and self-efficacy), and the perception of twenty-six features, were presented using a correlation matrix. The purpose of this correlation analysis is to provide a visual representation of the bivariate relationships among all thirty-five variables of this study instead of inferential testing. Inferential testing was conducted for Research question 2.2 using multiple regression, which is preferred over correlation analysis for inferential testing purposes. This is because multiple regression is a multivariate technique where the influence of each explanatory variable can be evaluated while holding other variables constant. SPSS17 and the open-source R statistical program were used to run these statistical analyses.

#### Sample

The survey was administered to first- and second-year undergraduates from the School of Engineering and Computer Science at a local university. Participants took an average of fifteen minutes to complete the survey. A total of 277 respondents (210 males, 58 females, 9 not reported; mean age = 21 years) participated in the study (see Table 2). Of the 277 respondents, 69% (n = 191) rated themselves as intermediate searchers, followed by 19.1% (n = 53) novice searchers, and 11.9% (n = 33) expert searchers. The respondents were frequent users of the Internet, with 43.3% using the Internet on a daily basis, and 41.5% who had been using the Internet for more than five years.

<table class="center" style="width:50%"><caption>  
Table 2: Profiles of respondents (N=277)</caption>

<tbody>

<tr>

<th colspan="2">Sex</th>

</tr>

<tr>

<td>Male</td>

<td>210 (75.8%)</td>

</tr>

<tr>

<td>Female</td>

<td>58 (20.9%)</td>

</tr>

<tr>

<td>Not reported</td>

<td>9 (3.2%)</td>

</tr>

<tr>

<td colspan="2"> </td>

</tr>

<tr>

<th colspan="2">Competency as online searcher</th>

</tr>

<tr>

<td>Novice searcher</td>

<td>53 (19.1%)</td>

</tr>

<tr>

<td>Intermediate searcher</td>

<td>191 (69%)</td>

</tr>

<tr>

<td>Expert searcher</td>

<td>33 (11.9%)</td>

</tr>

<tr>

<td colspan="2"> </td>

</tr>

<tr>

<th colspan="2">Experience with online systems</th>

</tr>

<tr>

<td><1 years</td>

<td>31 (11.2%)</td>

</tr>

<tr>

<td>1-2 years</td>

<td>37 (13.4%)</td>

</tr>

<tr>

<td>2-3 years</td>

<td>28 (10.1%)</td>

</tr>

<tr>

<td>3-4 years</td>

<td>27 (9.7%)</td>

</tr>

<tr>

<td>4-5 years</td>

<td>39 (14.1%)</td>

</tr>

<tr>

<td>> 5 years</td>

<td>116 (41.5%)</td>

</tr>

<tr>

<td colspan="2"> </td>

</tr>

<tr>

<th colspan="2">Frequency of online systems usage</th>

</tr>

<tr>

<td>Never</td>

<td>6 (2%)</td>

</tr>

<tr>

<td>Once a month</td>

<td>7 (2.5%)</td>

</tr>

<tr>

<td>Several times / month</td>

<td>37 (13.4%)</td>

</tr>

<tr>

<td>Several times / week</td>

<td>107 (38.6%)</td>

</tr>

<tr>

<td>Daily</td>

<td>120 (43.3%)</td>

</tr>

</tbody>

</table>

The internal consistency of the self-efficacy ratings was evaluated using SPSS. The reliability analysis yielded a Cronbach's alpha of .817, which is better than the generally accepted level of 0.7 ([Field 2009](#fie09)). Table 3 shows the ratings for self-efficacy in information searching. Out of a maximum of five, the average rating across all five aspects was 3.7 (SD = 0.51). The score for developing successful search strategies (M = 3.6) was slightly lower than for other aspects. Respondents reported higher self-efficacy for identifying and accessing sources (M = 3.76). Overall, the mean score for all aspects was above 3.5\. This indicates that most respondents perceived themselves as quite competent in the main aspects of information seeking.

<table class="center"><caption>  
Table 3: Self-efficacy in information seeking </caption><colgroup><col span="6"></colgroup> 

<tbody>

<tr>

<th>Aspects of information seeking</th>

<th>n</th>

<th>Min</th>

<th>Max</th>

<th>Mean</th>

<th>SD</th>

</tr>

<tr>

<td>Formulating questions based on information needs</td>

<td>276</td>

<td>1</td>

<td>5</td>

<td>3.7</td>

<td>0.7</td>

</tr>

<tr>

<td>Identifying potential sources of information</td>

<td>276</td>

<td>2</td>

<td>5</td>

<td>3.76</td>

<td>0.64</td>

</tr>

<tr>

<td>Developing successful search strategies</td>

<td>277</td>

<td>2</td>

<td>5</td>

<td>3.6</td>

<td>0.68</td>

</tr>

<tr>

<td>Accessing sources of information, including computer-based technologies</td>

<td>277</td>

<td>2</td>

<td>5</td>

<td>3.77</td>

<td>0.71</td>

</tr>

<tr>

<td>Evaluating information</td>

<td>277</td>

<td>2</td>

<td>5</td>

<td>3.7</td>

<td>0.64</td>

</tr>

<tr>

<td>**Overall information seeking self-efficacy**</td>

<td>**275**</td>

<td>**2**</td>

<td>**5**</td>

<td>**3.7**</td>

<td>**0.51**</td>

</tr>

</tbody>

</table>

## Results

### Research question 1.1\. Important design features

Table 4 shows the importance rating of the top ten features. The top three features were: (a) presentation of results in a simple, uncluttered interface; (b) display search options in order of usage frequency; and (c) provision of more search options.

<table class="center"><caption>  
Table 4: Top ten features </caption><colgroup><col span="6"></colgroup> 

<tbody>

<tr>

<th>Rank</th>

<th>Item no.</th>

<th>Features</th>

<th>n</th>

<th>Mean</th>

<th>SD</th>

</tr>

<tr>

<td>1</td>

<td>2_1</td>

<td>Have search results list formatted and displayed in a simple, uncluttered interface would help identify relevant documents more easily</td>

<td>277</td>

<td>4.26</td>

<td>0.68</td>

</tr>

<tr>

<td>2</td>

<td>1_1</td>

<td>Display search options in order of the most commonly used options (e.g., title, author, year of publication)</td>

<td>277</td>

<td>4.13</td>

<td>0.71</td>

</tr>

<tr>

<td>3</td>

<td>1_2</td>

<td>Provide more search options (e.g., search by title, author, abstract) for better query formulation</td>

<td>276</td>

<td>4.07</td>

<td>0.67</td>

</tr>

<tr>

<td>4</td>

<td>2_3</td>

<td>Rank the items in the search results list by percentage of relevance</td>

<td>277</td>

<td>4.02</td>

<td>0.81</td>

</tr>

<tr>

<td>5</td>

<td>1_3</td>

<td>Allow the use of simple, intuitive commands such as AND, OR, NOT in basic search</td>

<td>277</td>

<td>3.91</td>

<td>0.86</td>

</tr>

<tr>

<td>6</td>

<td>2_6</td>

<td>Highlight the query words in the search results list</td>

<td>277</td>

<td>3.91</td>

<td>0.78</td>

</tr>

<tr>

<td>7</td>

<td>3_4</td>

<td>Provide a feature to "find more documents like this one" for each search result shown</td>

<td>276</td>

<td>3.83</td>

<td>0.7</td>

</tr>

<tr>

<td>8</td>

<td>3_3</td>

<td>Highlight search query words in the document text retrieved from the search</td>

<td>277</td>

<td>3.81</td>

<td>0.7</td>

</tr>

<tr>

<td>9</td>

<td>2_2</td>

<td>In the search results list, the system categorizes documents based on document types, so that results would be grouped by journals, conference proceedings, etc.</td>

<td>277</td>

<td>3.81</td>

<td>0.77</td>

</tr>

<tr>

<td>10</td>

<td>3_5</td>

<td>Provide an indication to show that you have already reviewed, opened, or downloaded this document previously</td>

<td>276</td>

<td>3.8</td>

<td>0.85</td>

</tr>

</tbody>

</table>

#### Research questions 1.2\. Grouping of design features

The internal consistency of the self-efficacy ratings was evaluated using SPSS. The reliability analysis yielded a Cronbach's alpha of 0.817, which is better than the generally accepted level of 0.7 ([Field 2009](#fie09)). Table 3 shows the ratings for self-efficacy in information searching. Out of a maximum of five, the average rating across all five aspects was 3.7 (SD = 0.51). The score for developing successful search strategies (M = 3.6) was slightly lower than for other aspects. Respondents reported higher self-efficacy for identifying and accessing sources (M = 3.76). Overall, the mean score for all aspects was above 3.5\. This indicates that most respondents perceived themselves as quite competent in the main aspects of information seeking.

For each feature group, the average importance score was calculated. The main characteristics of each group are characterised, and the seven factors are presented in descending order of each group's average importance score:

*   Highest rank - Query formulation features (factor 5). Items include: 1_1 and 1_2 (M=4.1, SD=0.58). These features help users formulate queries by allowing more search fields for users to select different search options.
*   Second rank - Search results grouping and sorting (factor 6). Items include: 2_3 2_5 2_2, and 2_1\. The average importance score is 3.94 (SD=0.49). These features support subjective relevance judgments by grouping documents of similar types and sorting them by percentage of relevance.
*   Third rank - Supportive visuals (factor 3). Items include: 3_3, 3_4 and 3_5\. The average importance score is 3.78 (SD=0.58). These features help to draw users' attention to the query terms found in the documents and indicate whether a document has been reviewed, opened, or downloaded before.
*   Fourth rank - Advanced search reatures (factor 7). Items include: 1_4, and 1_3\. The average importance score is 3.73 (SD=0.65). This includes advance search functions such as command-line searching and Boolean searching.
*   Fifth rank - Direct search results evaluation (factor 1). Items include: 3_9, 3_8, 3_7, and 3_6\. The average importance score is 3.73 (SD=0.54). These features support evaluation of individual search results. They direct users to view the content of the search results, such as links to a document's full text or its table of contents.
*   Sixth rank - Results Listing Features (factor 4). Items include: 2_7 2_6 2_8, and 2_9\. The average importance score is 3.53 (SD=0.57). Features of factor 4 focus on the results list, such as including document abstracts with the list and highlighting query terms in the results list.
*   Seventh rank - Supportive chaining features (factor 2). Items include: 1_5 1_6, 3_1 2_4, 3_10, 3_2, and 2_10\. The average importance score is 3.48 (SD=0.50). Features in factor 2 provide links to external documents (such as search tutorials) and external resources (e.g., links to document authors), and to domain experts (i.e., forums).

### Research question 2\. Individual characteristics and rating of design features

#### Research question 2.1\. Bivariate relationships

The relationships among individual characteristics, self-efficacy in information seeking, and the importance ratings for all 26 features are presented in the [Appendix](#app), Figure 2\. This study included ordinal variables such as perceived competence as an online searcher and frequency of internet use. Kendall's tau-b (?b), a non-parametric measure for handling ordinal data, was used in the correlation analysis. Sex is a dichotomous variable, thus, the point biserial correlation coefficient (rpb) is used for this variable ([Field 2009](#fie09)). These correlation coefficients were calculated using R, and the resultant correlation matrix was plotted using the corrgram package in R ([Friendly 2002](#fri02)). The darker shade indicates a stronger correlation. An right-sloping diagonal line suggests a positive relationship and a left-sloping line, a negative relationship.

Several general patterns can be observed. First, male respondents tended to report having more experience with the Internet and online database searching. They also reported higher self-efficacy in all five aspects of information searching. Interestingly, they tended to give slightly lower importance scores to most features when compared to female respondents. Other than sex, generally, individual characteristics such as higher frequency of Internet use were positively associated with a higher importance rating for most design features. Negative relationships were found for a few features. Expert searchers found search tutorials and search examples (item 1_6) and records of their search history (item 2_4) less important, for example.

#### Research question 2.2\. Multivariate analysis

Multivariate analyses were conducted to probe further the relationships among individual characteristics and design-feature preference. The study tested nine explanatory factors: (a) sex; (b) years of online experience; (c) perceived competence as an online searcher; (d) frequency of internet use; (e) self-efficacy in question formulation; (f) self-efficacy in identification of sources; (g) self-efficacy in developing search strategies; (h) self-efficacy in accessing information sources; and (i) self-efficacy in evaluating information.

Seven multiple regressions were conducted with R to test whether these factors contribute to different ratings for each of the seven design feature groups discussed in Research question 1.2\. Individual characteristics were measured as categorical variables. They were analysed using the dummy coding method. Prior to the analysis, a multicollinearity diagnostic was conducted for each of the multiple regression equations using generalized variance inflation factors (GVIF). A GVIF1 with 2 degrees of free value larger than 2 indicates a multicollinearity problem ([Fox and Monette 1992](#fox92)), which is a situation in which the correlations among variables are problematically high. For all seven equations in this study, the diagnostic results showed that all nine variables yielded a GVIF1/2df value smaller than two. This suggests that the variables have no significant multicollinearity problem.

The multiple regression findings (see [Appendix](#app),Table 6) show significant influences for perceived competence as an online searcher, years of online experience, frequency of Internet use, and the five aspects of information seeking self-efficacy.

The analysis found that individuals with higher question formulation self-efficacy were more likely to deem factor group 1 direct search results evaluation, group 2 supportive chaining, group 4 results listing, and group 6 results grouping and sorting as important. Those with higher self-efficacy in source identification, on the other head, tended to give group 3 supportive visuals higher scores. Respondents with higher self-efficacy in developing search strategies preferred group 7 advanced search features (factor 7). Those with higher efficacy in accessing sources rated group 5 query formulation features and group 6 search results grouping and sorting as important. Respondents with higher self-efficacy in evaluating information were more likely to rate factor group 1 direct search results evaluation and group 4 results listing features higher.

Generally, frequent online system users tend to give higher ratings to most features than infrequent users. They gave a statistically significant higher rating for supportive visuals and search results grouping and sorting features, for example. Respondents with longer online experience also appreciate the query formulation and the search results grouping and sorting features. This may suggest a mutually reinforcing cycle. With increased exposure to certain system features, users may become more comfortable with those functions. Familiarity can contribute to positive evaluations of information systems and more usage of those information resources ([Barrett _et al._ 1968](#bar68); [Xie and Joo 2009](#xie09)), which in turn leads to more familiarity. Conversely, this suggests that information professionals may want to have prolonged instead of one-time training with reluctant users of academic databases, such that they can progressively gain familiarity with advanced features over a period of time ([Kim and Sin 2011](#kim11)).

On the other hand, other things being equal, competence in online searching showed negative relationships with many feature ratings. Expert searchers were significantly more likely to rate direct search results evaluation as less important. This may be that expert searchers are more confident with their own ability in judging relevance using a host of contextual cues. They may feel less need to rely on basic features such as links to the document's table of content. Recently, many academic information retrieval systems have move towards simpler search interfaces. There have been concerns among educators and information professionals that this may lead to dumbing down of search functionalities that may adversely affect advanced or professional users ([Howard and Wiebrands 2011](#how11)). How to enhance the customisability of information systems, such that they effectively support users with varying experience, skills, and expectations is an area that needs considerable attention.

Sex was not significant in the multivariate analysis. This is in line with the views that ascribed characteristics such as gender are not as crucial in information behaviour, after perceptual and behaviour factors are taken into account ([Zweizig and Dervin 1977](#zwe77)). Compared to situations in which behaviour is mostly shaped by biological factors, the stronger influence of perceptual and behaviour factors here suggests that information professionals and system designers have more room in contributing to effective individual information behaviour through system design and user education.

## Discussion

In the development of information systems, system testing often involves only a small number of participants in an observational study. The current study shows the usefulness of survey research in collecting the views of a larger sample of actual users. User surveys can complement usability testing and provide better understanding of diverse individuals' subjective needs. The study found that most participants, including experienced users, rated non-topical related features rather highly. This suggests a need for system designers to move beyond system relevance to incorporate more features that support subjective relevance judgment.

In addition, the highest-rated system features belong to stage 1 (before executing the search) and stage 2 (executing an action). Stage 3 features for evaluation are not considered so crucial. Kuhlthau's information search process model helps shed light on these findings. The model shows that individuals feel more uncertainty and confusion at the beginning of the search process, such as the initiation or the exploration stages. Similarly, at the sub-task level, users may also feel unsure at the beginning stage of the process. This uncertainty may contribute to the need for stronger support from information systems, thus translating to high scores for features at sub-task stages 1 and 2\. System designers may want to explore ways to provide more features supporting the earlier stages of the search process.

Previous studies have noted the importance of domain knowledge in effective searching. Others have tested the influence of computer skills. This study explored a different angle and found that information literacy skills, such as question formulation and evaluation of information, were significant factors in the choice of preferred features. When creating information delivery systems, developers may want to take into account the varying information literacy skills among users. Specifically, individuals with lower information-seeking self-efficacy and skills may require more attention. This is especially because these users may become frustrated with information systems quite quickly ([Kim and Sin 2007](#kim07)), which leads to less use of these resources.

The R<sup>2</sup> of the multiple regression analyses ranged from .1 to .19\. That is, the factors investigated here explained about 10% to 19% of the variance in preference of system features. This suggests that future studies interested in predicting feature preference may want to include extra variables. These include: task characteristics such as task types and complexity ([Vakkari 1999](#vak99)); respondents' domain knowledge and interest in topic ([Ruthven _et al._ 2007](#rut07)); individual characteristics such as affective, cognitive and learning styles ([Ford _et al._ 2001](#for01)); and the fit or interaction between individual style and tasks ([Kim and Allen 2002](#kim02)).

This study was a non-probability sampling of participants in a specific subject domain. It focused on testing relationships among participants, and was not aimed at population generalisation. Future studies may conduct random samplings of different populations to test the effect of disciplinary differences. Also worth pursuing is research on design features that support subjective relevance judgment in everyday-life information-seeking. In terms of data collection methods, including a larger-scale focus group and observation will provide additional rich data on the reasons behind user preferences for specific features. New studies may also ask respondents to group the features and map each feature to specific types of subjective relevance. Standardised information literacy assessment instruments can be employed to complement measures of information searching self-efficiency. Additionally, the features elicited from respondents can be incorporated into an information-delivery-system prototype. Further experiments can then be conducted to test the extent to which these features help users make subjective relevance judgments.

In conclusion, the study findings suggest that sensitivity to user differences and their levels of information seeking self-efficacy can assist in the development of more relevant retrieval systems. With a strong research tradition in studying complex and subjective human behaviour and the fluidity of the information search process, the information behaviour field has much to offer to a more user-centred and context-aware information system design.

## Acknowledgements

The authors would like to thank the following students who conducted the user study: Lindsay Goile, Pei-Chee Law, Seo-Lay Wee & Sze-Hwee Poh, and the students who participated in the focus group and the survey. We would also like to thank the anonymous reviewers and the participants of the ISIC 2012 conference for their helpful comments.

## About the authors

**Yin-Leng Theng** is the Associate Chair (Research) and an Associate Professor in the Wee Kim Wee School of Communication and Information, Nanyang Technological University. She received her Bachelor of Science degree from the National University of Singapore and her PhD from Middlesex University. She can be contacted at: [TYLTHENG@ntu.edu.sg](mailto:TYLTHENG@ntu.edu.sg).  
**Sei-Ching Joanna Sin** is an Assistant Professor in the Wee Kim Wee School of Communication and Information, Nanyang Technological University. She received her Bachelor of Social Science degree from the The Chinese University of Hong Kong and her PhD in Library and Information Studies from the University of Wisconsin-Madison. She can be contacted at: [joanna.sin@ntu.edu.sg](mailto:joanna.sin@ntu.edu.sg).

#### References

*   Anderson, T. D. (2005). [Relevance as process: Judgements in the context of scholarly research](http://www.webcitation.org/6AzU83LR7). _Information Research_, **10**(2). Retrieved 27 September 2012, from http://InformationR.net/ir/10-2/paper226.html (Archived by WebCite&REG; at http://www.webcitation.org/6AzU83LR7).
*   Barrett, G. V., Thornton, C. L. & Cabe, P. A. (1968). Human factors evaluation of a computer based information storage and retrieval system. _Human Factors_, **10**(4), 431-436.
*   Barry, C. L. & Schamber, L. (1998). Users' criteria for relevance evaluation: a cross-situational comparison. _Information Processing & Management_, **34**(2-3), 219-236.
*   Borlund, P. (2003). The concept of relevance in IR. _Journal of the American Society for Information Science and Technology_, **54**(10), 913-925.
*   Carroll, J. (2000). _Making use: scenario-based design of human-computer interactions_. Cambridge, MA: MIT Press.
*   Case, D. O. (2008). _Looking for information: a survey of research on information seeking, needs, and behavior._ (3rd ed.) Bingley, UK: Emerald.
*   Case, D. O., Andrews, J. E., Johnson, J.D. & Allard, S. L. (2005). Avoiding versus seeking: the relationship of information seeking to avoidance, blunting, coping, dissonance, and related concepts. _Journal of the Medical Library Association_, **93**(3), 353-362.
*   Chen, Z. & Xu, Y. (2005). User-oriented relevance judgment: a conceptual model. In _Proceedings of the 38th Hawaii International Conference on System Sciences_. (p. 101.2) Washington, DC: IEEE Computer Society
*   Cosijn, E. & Ingwersen, P. (2000). Dimensions of relevance. _Information Processing & Management_, **36**(4), 533-550.
*   Dervin, B. & Nilan, M. (1986). Information needs and uses. _Annual Review of Information Science and Technology_, **21**, 3-33.
*   Field, A. (2009). _Discovering statistics using SPSS_ (3rd ed.). Los Angeles, CA: Sage Publications.
*   Fisher, K. E. & Julien, H. (2009). Information behavior. _Annual Review of Information Science and Technology_, **43**, 317-358.
*   Ford, N., Miller, D. & Moss, N. (2001). The role of individual differences in internet searching: an empirical study. _Journal of the American Society for Information Science and Technology_, **52**(12), 1049-1066.
*   Fox, J. & Monette, G. (1992). Generalized collinearity diagnostics. _Journal of the American Statistical Association_, **87**(417), 178-183.
*   Friendly, M. (2002). Corrgrams: exploratory displays for correlation matrices. _The American Statistician_, **56**(4), 316-324.
*   Froehlich, T. J. (1994). Relevance reconsidered - towards an agenda for the 21st century. Introduction to special topic issue on relevance research. _Journal of the American Society for Information Science_, **45**(3), 124-134.
*   Hair, J. F., Black, W. C., Babin, B. J. & Anderson, R. E. (2010). _Multivariate data analysis_ (7th ed.). Upper Saddle River, NJ: Prentice Hall.
*   Howard, D. & Wiebrands, C. (2011). [_Culture shock: Librarians' response to web scale search_.](http://www.webcitation.org/6BjEvVLvR)) Paper presented atALIA 2011 Information Online Conference, Australian Library and Information Association, Sydney, N.S.W. Retrieved 27 September 2012, from http://ro.ecu.edu.au/ecuworks/6206/ (Archived by WebCite at http://www.webcitation.org/6BjEvVLvR).
*   Kagolovsky, Y. & Moehr, J. R. (2004). A new look at information retrieval evaluation: proposal for solutions. _Journal of Medical Systems_, **28**(1), 103-116.
*   Kelly, D. (2004). _Understanding implicit feedback and document preference: a naturalistic user study_. Unpublished doctoral dissertation, Rutgers University, New Brunswick, New Jersey, USA.
*   Kim, K.-S. & Allen, B. (2002). Cognitive and task influences on web searching behavior. _Journal of the American Society for Information Science and Technology_, **53**(2), 109-119.
*   Kim, K.-S. & Sin, S.-C. J. (2007). Perception and selection of information sources by undergraduate students: Effects of avoidant style, confidence, and personal control in problem-solving. _Journal of Academic Librarianship_, **33**(6), 655-665.
*   Kim, K.-S. & Sin, S.-C. J. (2011). Selecting quality sources: bridging the gap between the perception and use of information sources. _Journal of Information Science_, **37**(2), 178-188.
*   Kuhlthau, C. C. (1991). Inside the search process: information seeking from the user's perspective. _Journal of the American Society for Information Science_, 42(5), 361-371.
*   Lee, S.S., Theng, Y.L. & Goh, D.H.L. (2007). Creative information seeking part II: empirical verification. _Aslib Proceedings_, **59**(3), 205-221
*   Lee, S.S., Theng, Y.L., Goh, D.H.L. & Foo, S.S.B. (2006). An exploratory factor analytic approach to understand design features for academic learning environments. In _ECDL'06 Proceedings of the 10th European conference on Research and Advanced Technology for Digital Libraries_, (pp. 315-328). Berlin, Heidelberg: Springer Verlag. (Lecture Notes in Computer Science, 4172) 315-328.
*   Lee, S.S., Theng, Y.L., Goh, D. & Foo, S. (2004). Subjective relevance: implications on digital libraries for experts and novices. In _Proceedings of the 7th International Conference on Asian Digital Libraries._ (pp. 453-457) Berlin, Heidelberg: Springer Verlag. (Lecture Notes in Computer Science, 3334).
*   Lowe, C.A. & Eisenberg, M.B. (2005). Big6 skills for information literacy. In K. E. Fisher, S. Erdelez & L. McKechnie (Eds.), _Theories of information behavior_ (pp. 63-68). Medford, N.J: Information Today.
*   Nahl, D. (2005). Affective and cognitive information behavior: Interaction effects in internet use. _Proceedings of the American Society for Information Science and Technology_, **42**(1).
*   Norman, D.A. (1988). _The psychology of everyday things_. New York, NY: Basic Books.
*   Ruthven, I., Baillie, M. & Elsweiler, D. (2007). The relative effects of knowledge, interest and confidence in assessing relevance. _Journal of Documentation_, **63**(4), 482-504.
*   Saracevic, T. (1996). Relevance reconsidered. In P. Ingwersen & N. O. Pors (Eds.), _Information science: Integration in perspectives_. (pp. 201-218). Copenhagen, Denmark: Royal School of Library and Information Science.
*   Saracevic, T. (2007a). Relevance: a review of the literature and a framework for thinking on the notion in information science. Part II: Nature and manifestations of relevance. _Journal of the American Society for Information Science and Technology_, **58**(13), 1915-1933.
*   Saracevic, T. (2007b). Relevance: a review of the literature and a framework for thinking on the notion in information science. Part III: Behavior and effects of relevance. _Journal of the American Society for Information Science and Technology_, **58**(13), 2126-2144.
*   Savolainen, R. (2006). Time as a context of information seeking. _Library & Information Science Research_, **28**(1), 110-127.
*   Tang, P. & Solomon, P. (2001). Use of relevance criteria across stages of document evaluation: on the complementarity of experimental and naturalistic studies. _Journal of the American Society for Information Science and Technology_, **52**(8), 676-685.
*   Taylor, A.R., Cool, C., Belkin, N.J. & Amadio, W.J. (2007). Relationships between categories of relevance criteria and stage in task completion. _Information Processing & Management_, **43**(4), 1071-1084.
*   Taylor, R.S. (1962). The process of asking questions. _American Documentation_, **13**(4), 391-396.
*   Vakkari, P. (1999). Task complexity, problem structure and information actions - integrating studies on information seeking and retrieval. _Information Processing & Management_, **35**(6), 819-837.
*   Vakkari, P. & Hakala, N. (2000). Changes in relevance criteria and problem stages in task performance. _Journal of Documentation_, **56**(5), 540-562.
*   Vakkari, P., Savolainen, R. & Dervin, B. (1997). _Information seeking in context_. London: Taylor Graham.
*   Wilson, T. D. (1999). Models in information behaviour research. _Journal of Documentation_, **55**(3), 249-270.
*   Wilson, T. D. (2000). Human information behavior. _Informing Science_, **3**(2), 49-55.
*   Xie, I. & Joo, S. (2009). Selection of information sources: accessibility of and familiarity with sources, and types of tasks. _Proceedings of theAmerican Society for Information Science and Technology_, **46**(1), 1-18.
*   Zweizig, D. & Dervin, B. (1977). Public library use, users, uses: advances in knowledge of characteristics and needs of the adult clientele of American public libraries. _Advances in librarianship_, **7**, 232-255).

<section>  

<table class="footer" style="border-spacing:10;">

<tbody>

<tr>

<td colspan="3" style="text-align:center; background-color: #5E96FD; color: white; font-family: verdana; font-size: small; font-weight: bold;">Find other papers on this subject</td>

</tr>

<tr>

<td style="text-align:center; vertical-align:top;">

<form method="get" action="http://scholar.google.com/scholar" target="_blank">

<table class="footer">

<tbody>

<tr>

<td style="white-space: nowrap; vertical-align:top; text-align:center; height:32;"><input type="hidden" name="q" value="&quot;self-efficacy&quot; &quot;relevance judgements&quot;">  
<input type="submit" name="sa" value="Scholar Search" style="font-size: small; font-family: Verdana; font-weight: bold;"> <input type="hidden" name="num" value="100"></td>

</tr>

</tbody>

</table>

</form>

</td>

<td style="vertical-align:top; text-align:center;">

<form method="get" action="http://www.google.com/custom" target="_blank">

<table class="footer">

<tbody>

<tr>

<td style="white-space: nowrap; vertical-align:top; text-align:center; height:32;"><input type="hidden" name="q" value="&quot;self-efficacy&quot; &quot;relevance judgements&quot;">  
<input type="submit" name="sa" value="Google Search" style="font-family: Verdana; font-weight: bold; font-size: small;"> <input type="hidden" name="client" value="pub-5081678983212084"> <input type="hidden" name="forid" value="1"> <input type="hidden" name="ie" value="ISO-8859-1"> <input type="hidden" name="oe" value="ISO-8859-1"> <input type="hidden" name="cof" value="GALT:#0066CC;GL:1;DIV:#999999;VLC:336633;AH:center;BGC:FFFFFF;LGC:FF9900;LC:0066CC;LC:0066CC;T:000000;GFNT:666666;GIMP:666666;FORID:1;"> <input type="hidden" name="hl" value="en"></td>

</tr>

</tbody>

</table>

</form>

</td>

<td style="vertical-align:top; text-align:center;">

<form method="get" action="http://www.bing.com" target="_blank">

<table class="footer">

<tbody>

<tr>

<td style="white-space: nowrap; vertical-align:top; text-align:center; height:32;"><input type="hidden" name="q" value="&quot;self-efficacy&quot; &quot;relevance judgements&quot;">  
<input type="submit" name="sa" value="Bing" style="font-size: small; font-family: Verdana; font-weight: bold;"> <input type="hidden" name="num" value="100"></td>

</tr>

</tbody>

</table>

</form>

</td>

</tr>

</tbody>

</table>

<div style="text-align:center;">Check for citations, [using Google Scholar](http://scholar.google.co.uk/scholar?hl=en&q=http://informationr.net/ir/17-4/paper536.html&btnG=Search&as_sdt=2000)</div>

<div style="text-align:center;">

<div style="text-align:center;" class="addthis_toolbox addthis_default_style"><a class="addthis_button_facebook_like" fb:like:layout="button_count"></a><a class="addthis_button_tweet"></a><a class="addthis_counter addthis_pill_style"></a></div>

</div>

* * *

## Appendix

<figure>![Figure 2\. Correlation matrix](p536fig2.jpg)

<figcaption>  
Figure 2\. Correlation matrix</figcaption>

</figure>

<table class="center" style="width:95%;"><caption>  
Table 5: Factor loadings and eigenvalues</caption>

<tbody>

<tr>

<th rowspan="2">Item no.</th>

<th rowspan="2">Features</th>

<th colspan="7">Factor</th>

</tr>

<tr>

<th>1</th>

<th>2</th>

<th>3</th>

<th>4</th>

<th>5</th>

<th>6</th>

<th>7</th>

</tr>

<tr>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>3_9</td>

<td>Provide URL links to full-text documents that are referenced in the current document or search results</td>

<td>0.785</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>3_8</td>

<td>Specify the pages in which the query words appear in the document's contents and provide direct links to the pages</td>

<td>0.703</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>3_7</td>

<td>As part of the search results, the system also provides a URL to the actual journal for general information (e.g., publisher's information, accessibility rights) about that document source</td>

<td>0.691</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>3_6</td>

<td>Allow you to view the table of contents in the source document if its full-text is not available</td>

<td>0.537</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>1_5</td>

<td>Allow you to change from one subject area to another when searching</td>

<td> </td>

<td>0.632</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>1_6</td>

<td>Provide search tutorials and search examples to help query formulation (e.g., online help or system suggested examples)</td>

<td> </td>

<td>0.622</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>3_1</td>

<td>Include the email address(es) of the author(s) of the retrieved document(s)</td>

<td> </td>

<td>0.582</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>2_4</td>

<td>Allow you to review the search history of past queries submitted and the corresponding search results list</td>

<td> </td>

<td>0.573</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>3_10</td>

<td>Provide access to a subject specific forum, where you can seek others' views on the documents retrieved or any other related matter</td>

<td> </td>

<td>0.496</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>3_2</td>

<td>Indicate how many times a document in the search results has been cited or used by others</td>

<td> </td>

<td>0.428</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>2_10</td>

<td>Recommend search tips based on your query</td>

<td> </td>

<td>0.376</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>3_3</td>

<td>Highlight search query words in the document text retrieved from the search</td>

<td> </td>

<td> </td>

<td>0.761</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>3_4</td>

<td>Provide a feature to "find more documents like this one" for each search result shown</td>

<td> </td>

<td> </td>

<td>0.643</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>3_5</td>

<td>Provide an indication to show that you have already reviewed, opened, or downloaded this document previously</td>

<td> </td>

<td> </td>

<td>0.543</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>2_7</td>

<td>Provide each document's abstract in the search results list</td>

<td> </td>

<td> </td>

<td> </td>

<td>0.712</td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>2_6</td>

<td>Highlight the query words in the search results list</td>

<td> </td>

<td> </td>

<td> </td>

<td>0.548</td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>2_8</td>

<td>Show year of publication to indicate how current the document for each item in the search result list</td>

<td> </td>

<td> </td>

<td> </td>

<td>0.529</td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>2_9</td>

<td>Provide documentation to inform how search results are ranked</td>

<td> </td>

<td> </td>

<td> </td>

<td>0.484</td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>1_1</td>

<td>Display search options in order of the most commonly used options (e.g., title, author year of publication)</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td>0.687</td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>1_2</td>

<td>Provide more search options (e.g., search by title, author, abstract) for better query formulation</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td>0.665</td>

<td> </td>

<td> </td>

</tr>

<tr>

<td>2_3</td>

<td>Rank the items in the search results list by percentage of relevance</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td>0.725</td>

<td> </td>

</tr>

<tr>

<td>2_5</td>

<td>Search results list to provide a recommendation of documents nd related topics based on the query submitted</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td>0.525</td>

<td> </td>

</tr>

<tr>

<td>2_2</td>

<td>In the search results list, the system categorises documents based on document types, so that results would be grouped by journals, conference proceedings, etc.</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td>0.495</td>

<td> </td>

</tr>

<tr>

<td>2_1</td>

<td>Have search results list formatted and displayed in a simple, uncluttered interface would help identify relevant documents more easily</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td>0.461</td>

<td> </td>

</tr>

<tr>

<td>1_4</td>

<td>Provide a command line search option in the advanced search</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td>0.753</td>

</tr>

<tr>

<td>1_3</td>

<td>Allow the use of simple, intuitive commands such as AND, OR, NOT in basic search</td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td>0.662</td>

</tr>

<tr>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

<td> </td>

</tr>

<tr>

<td> </td>

<td>Eigenvalue</td>

<td>5.66</td>

<td>2.16</td>

<td>1.62</td>

<td>1.43</td>

<td>1.26</td>

<td>1.21</td>

<td>1.05</td>

</tr>

<tr>

<td> </td>

<td>% of Total Variance</td>

<td>21.76</td>

<td>8.31</td>

<td>6.22</td>

<td>5.49</td>

<td>4.83</td>

<td>4.67</td>

<td>4.03</td>

</tr>

</tbody>

</table>

<table class="center"><caption>  
Table 6: Multiple regression: standardized regression coefficients</caption>

<tbody>

<tr>

<th> </th>

<th colspan="2">Query formulation</th>

<th colspan="2">Search results grouping & sorting</th>

<th colspan="2">Supportive visuals</th>

<th colspan="2">Advance search features</th>

<th colspan="2">Direct search results</th>

<th colspan="2">Results listing</th>

<th colspan="2">Supportive chaining</th>

</tr>

<tr>

<th> </th>

<th colspan="2">Factor 5</th>

<th colspan="2">Factor 6</th>

<th colspan="2">Factor 3</th>

<th colspan="2">Factor 7</th>

<th colspan="2">Factor 1</th>

<th colspan="2">Factor 4</th>

<th colspan="2">Factor 2</th>

</tr>

<tr>

<th> </th>

<th colspan="2">(M=4.10)</th>

<th colspan="2">(M=3.94)</th>

<th colspan="2">(M=3.78)</th>

<th colspan="2">(M=3.73)</th>

<th colspan="2">(M=3.73)</th>

<th colspan="2">(M=3.53)</th>

<th colspan="2">(M=3.48)</th>

</tr>

<tr>

<td>Gender (Male)</td>

<td class="tdclass">-0.05</td>

<td>  </td>

<td class="tdclass">-0.04</td>

<td>  </td>

<td class="tdclass">-0.07</td>

<td>  </td>

<td class="tdclass">-0.11</td>

<td>  </td>

<td class="tdclass">-0.05</td>

<td>  </td>

<td class="tdclass">-0.02</td>

<td>  </td>

<td class="tdclass">-0.02</td>

<td>  </td>

</tr>

<tr>

<td>Competence as online searcher (Intermediate) </td>

<td class="tdclass">-0.04</td>

<td>  </td>

<td class="tdclass">-0.11</td>

<td>  </td>

<td class="tdclass">0.11</td>

<td>  </td>

<td class="tdclass">0.03</td>

<td>  </td>

<td class="tdclass">-0.05</td>

<td>  </td>

<td class="tdclass">0.13</td>

<td>  </td>

<td class="tdclass">-0.16</td>

<td>  </td>

</tr>

<tr>

<td>Competence as online searcher (Expert) </td>

<td class="tdclass">0.22</td>

<td>  </td>

<td class="tdclass">-0.87</td>

<td>  </td>

<td class="tdclass">0.18</td>

<td>  </td>

<td class="tdclass">0.78</td>

<td>  </td>

<td class="tdclass">-1.07</td>

<td>* </td>

<td class="tdclass">0.03</td>

<td>  </td>

<td class="tdclass">-0.73</td>

<td>  </td>

</tr>

<tr>

<td>Exp. with online systems (1-2 years) </td>

<td class="tdclass">0.38</td>

<td>  </td>

<td class="tdclass">0.1</td>

<td>  </td>

<td class="tdclass">0.06</td>

<td>  </td>

<td class="tdclass">-0.2</td>

<td>  </td>

<td class="tdclass">0.23</td>

<td>  </td>

<td class="tdclass">-0.19</td>

<td>  </td>

<td class="tdclass">0.43</td>

<td>  </td>

</tr>

<tr>

<td>Exp. with online systems (2-3 years)   </td>

<td class="tdclass">0.36</td>

<td>  </td>

<td class="tdclass">0.38</td>

<td>  </td>

<td class="tdclass">-0.11</td>

<td>  </td>

<td class="tdclass">-0.21</td>

<td>  </td>

<td class="tdclass">0.06</td>

<td>  </td>

<td class="tdclass">-0.37</td>

<td>  </td>

<td class="tdclass">0.13</td>

<td>  </td>

</tr>

<tr>

<td>Exp. with online systems (3-4 years)  </td>

<td class="tdclass">0.11</td>

<td>  </td>

<td class="tdclass">0.4</td>

<td>* </td>

<td class="tdclass">0.05</td>

<td>  </td>

<td class="tdclass">-0.03</td>

<td>  </td>

<td class="tdclass">0.16</td>

<td>  </td>

<td class="tdclass">-0.11</td>

<td>  </td>

<td class="tdclass">0.23</td>

<td>  </td>

</tr>

<tr>

<td>Exp. with online systems (4-5 years) </td>

<td class="tdclass">0.47</td>

<td>* </td>

<td class="tdclass">0.45</td>

<td>* </td>

<td class="tdclass">0.11</td>

<td>  </td>

<td class="tdclass">-0.06</td>

<td>  </td>

<td class="tdclass">0.14</td>

<td>  </td>

<td class="tdclass">-0.06</td>

<td>  </td>

<td class="tdclass">0.27</td>

<td>  </td>

</tr>

<tr>

<td>Exp. with online systems (> 5 years) </td>

<td class="tdclass">0.32</td>

<td>  </td>

<td class="tdclass">0.27</td>

<td>  </td>

<td class="tdclass">-0.01</td>

<td>  </td>

<td class="tdclass">0.03</td>

<td>  </td>

<td class="tdclass">0.06</td>

<td>  </td>

<td class="tdclass">-0.29</td>

<td>  </td>

<td class="tdclass">0.01</td>

<td>  </td>

</tr>

<tr>

<td>Freq. of usage (Once a month) </td>

<td class="tdclass">0.2</td>

<td>  </td>

<td class="tdclass">0.54</td>

<td>  </td>

<td class="tdclass">0.99</td>

<td>** </td>

<td class="tdclass">0.83</td>

<td>* </td>

<td class="tdclass">0.56</td>

<td>  </td>

<td class="tdclass">0.26</td>

<td>  </td>

<td class="tdclass">0.29</td>

<td>  </td>

</tr>

<tr>

<td>Freq. of usage (Several times / month) </td>

<td class="tdclass">0.13</td>

<td>  </td>

<td class="tdclass">0.45</td>

<td>* </td>

<td class="tdclass">0.52</td>

<td>** </td>

<td class="tdclass">0.17</td>

<td>  </td>

<td class="tdclass">0.31</td>

<td>  </td>

<td class="tdclass">0.15</td>

<td>  </td>

<td class="tdclass">0.19</td>

<td>  </td>

</tr>

<tr>

<td>Freq. of usage (Several times / week) </td>

<td class="tdclass">0.06</td>

<td>  </td>

<td class="tdclass">0.56</td>

<td>* </td>

<td class="tdclass">0.61</td>

<td>* </td>

<td class="tdclass">0.28</td>

<td>  </td>

<td class="tdclass">0.33</td>

<td>  </td>

<td class="tdclass">0.18</td>

<td>  </td>

<td class="tdclass">0.24</td>

<td>  </td>

</tr>

<tr>

<td>Freq. of usage (Daily) </td>

<td class="tdclass">0.07</td>

<td>  </td>

<td class="tdclass">1.48</td>

<td>  </td>

<td class="tdclass">1.77</td>

<td>* </td>

<td class="tdclass">0.92</td>

<td>  </td>

<td class="tdclass">1.25</td>

<td>  </td>

<td class="tdclass">0.4</td>

<td>  </td>

<td class="tdclass">0.72</td>

<td>  </td>

</tr>

<tr>

<td>Self-efficacy: question formulation </td>

<td class="tdclass">0.04</td>

<td>  </td>

<td class="tdclass">0.25</td>

<td>* </td>

<td class="tdclass">0.15</td>

<td>  </td>

<td class="tdclass">0.09</td>

<td>  </td>

<td class="tdclass">0.21</td>

<td>* </td>

<td class="tdclass">0.28</td>

<td>** </td>

<td class="tdclass">0.3</td>

<td>** </td>

</tr>

<tr>

<td>Self - efficacy: identification of sources</td>

<td rowspan="2" class="tdclass">0.06</td>

<td rowspan="2">  </td>

<td rowspan="2" class="tdclass">-0.12</td>

<td rowspan="2">  </td>

<td rowspan="2" class="tdclass">0.2</td>

<td rowspan="2">* </td>

<td rowspan="2" class="tdclass">-0.04</td>

<td rowspan="2">  </td>

<td rowspan="2" class="tdclass">0.12</td>

<td rowspan="2">  </td>

<td rowspan="2" class="tdclass">0.02</td>

<td rowspan="2">  </td>

<td rowspan="2" class="tdclass">-0.09</td>

<td rowspan="2">  </td>

</tr>

<tr>

<td>  
</td>

</tr>

<tr>

<td>Self-efficacy: developing search strategies </td>

<td class="tdclass">0.01</td>

<td>  </td>

<td class="tdclass">0.06</td>

<td>  </td>

<td class="tdclass">-0.03</td>

<td>  </td>

<td class="tdclass">0.19</td>

<td>* </td>

<td class="tdclass">-0.04</td>

<td>  </td>

<td class="tdclass">0.07</td>

<td>  </td>

<td class="tdclass">-0.01</td>

<td>  </td>

</tr>

<tr>

<td>Self-efficacy: accessing information sources </td>

<td class="tdclass">0.18</td>

<td>* </td>

<td class="tdclass">0.19</td>

<td>* </td>

<td class="tdclass">0.01</td>

<td>  </td>

<td class="tdclass">-0.05</td>

<td>  </td>

<td class="tdclass">0.04</td>

<td>  </td>

<td class="tdclass">-0.09</td>

<td>  </td>

<td class="tdclass">0.03</td>

<td>  </td>

</tr>

<tr>

<td>Self-efficacy: evaluating information </td>

<td class="tdclass">0.01</td>

<td>  </td>

<td class="tdclass">0.08</td>

<td>  </td>

<td class="tdclass">0.07</td>

<td>  </td>

<td class="tdclass">0.1</td>

<td>  </td>

<td class="tdclass">0.22</td>

<td>** </td>

<td class="tdclass">0.18</td>

<td>* </td>

<td class="tdclass">0.13</td>

<td>  </td>

</tr>

<tr>

<td>  
</td>

<td>  </td>

<td>  </td>

<td>  </td>

<td>  </td>

<td>  </td>

<td>  </td>

<td>  </td>

<td>  </td>

<td>  </td>

<td>  </td>

<td>  </td>

<td>  </td>

<td>  </td>

<td>  </td>

</tr>

<tr>

<td>R<sup>2</sup></td>

<td class="tdclass">0.11</td>

<td>  </td>

<td class="tdclass">0.19</td>

<td>  </td>

<td class="tdclass">0.15</td>

<td>  </td>

<td class="tdclass">0.13</td>

<td>  </td>

<td class="tdclass">0.16</td>

<td>  </td>

<td class="tdclass">0.12</td>

<td>  </td>

<td class="tdclass">0.1</td>

<td>  </td>

</tr>

</tbody>

</table>

