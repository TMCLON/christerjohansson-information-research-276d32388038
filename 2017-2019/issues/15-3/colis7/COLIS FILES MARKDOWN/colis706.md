#### vol. 15 no. 3, September, 2010

## Proceedings of the Seventh International Conference on Conceptions of Library and Information Science - "Unity in diversity"

# The social psychology of information use: seeking “friends”, avoiding “enemies”

#### [Birger Hjørland](#authors) and [Jeppe Nicolaisen](#authors)  
Royal School of Library and Information Science, Birketinget 6, DK-2300 Copenhagen S, Denmark

#### Abstract

> **Background.** The evaluation of information and information sources is not just about checking facts, but also involves social psychological relations between knowledge producers and users. In Social psychology so-called confirmation bias has been demonstrated by a number of empirical studies, i.e. that people prefer supporting to conflicting information when making decisions. However, experimental social psychology finds it difficult to say under which conditions confirmation bias may be a relevant strategy in information seeking and use.  
> **Argument.** This article suggests that we should turn to real life situations in order to study such kinds of cognitive bias.  
> **Elaboration.** The famous Burt-affair is used to illustrate the presence of confirmation bias in scientific research: Scientists tend to overlook errors in reported research if it is in line with their own theoretical views.  
> **Conclusion.** This has implications for the evaluation of information sources. The implications are outlined and discussed.

## Introduction

The use of information plays a central role in human problem solving and decision making processes. The reliability and validity of the information used is critical for the outcome of these processes. The use of biased or incorrect information may well lead to problem solving failure and to poor decision making. The critical assessment of information and information sources is therefore a vital step in all problem solving and decision making. We use the term _source criticism_ as a generic term for both information evaluation and source evaluation. In this connotation, source criticism is the study of how information and information sources should be evaluated for given tasks ([Wikipedia 2008](#ref17)). Many fields are contributing to this area of study, making source criticism a truly interdisciplinary research area. Epistemology, ethics, history, psychology, research methodology, science studies, and textual criticism, to name a few, are some of the contributing fields, and of course also the field of library and information science. Consequently, source criticism has many aspects, and an interdisciplinary approach is necessary if one wants to work professionally in this research area.

In this article we focus on one aspect that hitherto has been overlooked or neglected by information researchers. We want to address the question to what extent people prefer information that supports their favoured view compared to information that opposes it. This phenomenon is sometimes called _confirmation bias_ (e.g., [Schulz-Hardt, _et al._ 2000](#ref27)) and sometimes _congeniality bias_ (e.g., [Eagly and Chaiken 1993;](#ref04) [1998;](#ref05) [2005](#ref06)). Further, we want to discuss the consequences (if any) of such behaviour, and finally, we want to discuss what it takes to avoid it and thus what it takes to evaluate information and information sources critically. (Terms such as _positivism_ and other labels for epistemological views are used with different meanings in the literature. It is rather complicated, and epistemological positions are often re-interpreted, why the reader of this paper should not read any meaning into these terms other than what have been noticed in our use of them.)

Research on confirmation bias has been undertaken mainly by social psychologists and studied most extensively within the framework of dissonance theory. We will therefore start with a brief review of this work before turning to the discussion of the consequences. We will show that it is difficult to conclude whether confirmation bias is _good_ or _bad_ from the point of view of experimental social psychology. Instead we turn to the field of science studies and to a specific case involving confirmation bias that enables us to draw more firm conclusions. The case in question is the so-called _Burt-affair_ involving the controversy over whether the British educational psychologist Sir Cyril Burt committed fraud in his famous studies of the intelligence of separated monozygotic twins, and why it took so long before the (possible) fraud was discovered. Finally, we will use the same case as a starting point for our discussion about what it takes to avoid confirmation bias.

## Social psychology: confirmation bias

Research on confirmation bias has traditionally assumed that people are motivated to defend their attitudes and beliefs from challenges. Avoiding information likely to pose a challenge to an attitude or belief makes it easier to defend the same attitude or belief. Actively seeking information that confirms an attitude or belief similarly makes it easier to defend the same attitude or belief. Thus, people have traditionally been assumed to favour supportive information to unsupportive information, and it has traditionally been assumed that this preference actively influences human information search processes. ([Hart _et al._ 2009](#ref14)) argue that this assumption may be traced back to William James [(1890)](#ref18) and even to Francis Bacon ([1620] [1960](#ref30)), but acknowledge that the topic had not attained prominence among social psychologists until Leon Festinger's theory of cognitive dissonance ([Festinger 1957;](#ref07) [1964](#ref08)). Cognitive dissonance is an uncomfortable feeling caused by holding two conflicting positions simultaneously. Such positions may include attitudes, beliefs, ideas, and the awareness of one's behaviour. The theory of cognitive dissonance proposes that people have a motivational drive to reduce dissonance by changing their positions, or by justifying or rationalizing their positions. After having committed to a position, people will tend to gather supportive information and avoid or neglect unsupportive information to eliminate the uncomfortable feeling of cognitive dissonance. Hart _et al._ provide a good description of the typical test procedures for testing this theory:

> Typically, researchers have tested this congeniality principle in a laboratory paradigm in which participants select information from alternatives. Prior to this selection, participants make a decision (e.g., about the guilt of a defendant in a mock trial), form an attitude (e.g., toward a work of art), report an existing attitude (e.g., on abortion), or report a prior behaviour (e.g., whether they have smoked). Then participants are given an opportunity to receive information about the same issue (e.g., abortion, smoking) from a list of options usually presented as titles or abstracts of available articles. Typically half of these options support the participant's attitude, belief, or behaviour, and the other half contradict it. The researcher records the numbers of chosen articles that agree or disagree with each participant's attitude, belief, or behaviour. Selection of more articles that agree and fewer that disagree indicates a congeniality bias. Selection of more articles that disagree and fewer that agree indicates an uncongeniality bias. ([Hart _et al._ 2009](#ref14): 556)

Results of these tests have been reviewed qualitatively by Freedman and Sears ([1965](#ref10)), Cotton ([1985](#ref03)), and Frey ([1986](#ref11)), and quantitatively by Hart _et al._ ([2009](#ref14)). The first review by Freedman and Sears ([1965](#ref10)) included fourteen research reports. The reviewers found only little support for the theory. Later re-examinations by Cotton ([1985](#ref03)) and Frey ([1986](ref#11)) questioned this finding. Their reviews included twenty-nine and thirty-four research reports, respectively, and concluded that confirmation bias exists under a wide variety of circumstances consistent with the theory of cognitive dissonance. The first and to date only meta-analysis confirms this conclusion. Hart _et al._ ([2009](#ref14)) gathered twenty-one new research reports that had emerged since 1986 and analysed these together with the older reports. Findings of their meta-analysis clearly demonstrate confirmation bias: '_People are almost two times... more likely to select information congenial rather than uncongenial to their pre-existing attitudes, beliefs, and behaviors_' ([Hart _et al._ 2009: 579](#ref14)).

Social psychologists have long discussed whether the possible occurrence of confirmation bias should be actively prevented. Schulz-Hardt _et al._ ([2000](#ref27)) argue that the answer depends on the underlying model of _optimal_ decision making. They point to a position held by Janis (1982) and Nemeth & Rogers (1996), among others, that is based on the assumption that a careful examination of advantages and disadvantages of available alternatives is the best way to make decisions, and conclude that from this position confirmation bias is a problem that should be prevented. However, they argue, other researchers (e.g., Brunsson 1982) hold the position that '_preventing indecisiveness by immediately bolstering confidence and focusing on the opportunities of the preferred alternative often far outweigh the risk of overlooking serious disadvantages of the preferred alternative_' ([Schulz-Hardt _et al._ 2000: 667](#ref27)) Thus, from this position confirmation bias should not be prevented. Each position may be appropriate in specific contexts and it is impossible, therefore, from a general social psychology point of view to conclude for or against information search and use practices based on confirmation bias.

## Science studies: the Burt-affair

In this section we will focus on phenomena related to confirmation bias in a specific context, namely the context of science studies and more specifically in the context of the so-called _Burt-affair._

Sir Cyril Burt (1883-1971) is one of the most honoured and influential psychologists in the recent history of Psychology. He was Professor of Developmental Psychology at University College London, and was knighted in 1946 by King George VI.

Burt was possessed by the idea that poor people and the working class were regularly of inferior intelligence compared to middle and upper class. This belief led him to seek evidence for his conviction that intelligence is hereditary. He claimed to have conducted large and representative studies of various kinship correlations in intellence quotient (IQ) test scores. Among these were the only reported correlations between the IQs of second cousins, of uncles and nephews and of children and their parents when the parents were at the same age as the children ([Tucker, 1994: 335](#ref28)). However, his most famous work is indisputably his study (and later updates) of monozygotic twins reared apart. The best and most objective method for answering the question about the nature of intelligence scientifically is regarded by many researchers to be the study of monozygotic twins reared apart. Monozygotic twins have identical genes, hence, all differences may be attributed to the environment. However, what constitutes a _different environment_ is not easy to specify because also children reared in the same family may experience different _environments_. Because one of the most important alternative theories of intelligence consider social class the most important factor for educational opportunities, monozygotic twins reared in different socio-economic environments are usually considered the most important object of study in this field.

Tucker ([1994: 335](#ref28)) explains that not only did Burt's study involve the largest number of separated twin pairs at the time, and not only did it produce the highest estimate of heritability for IQ, but, of particular significance, it reported no correlations between the socio-economic status of the homes in which the twins were raised. This was taken as clear evidence for the theory that intelligence is hereditary not only by Burt himself, but also by prominent researchers in the field at large:

> The uniqueness of his data together with his large sample sizes made Burt's calculations 'the most satisfactory attempt' to estimate the heritability of IQ, according to [Arthur] Jensen. Burt's study of separated twins, in particular, was considered the butter on the hereditarian bread. [Arthur] Jensen termed it 'the most valuable' of all the separated twin research, citing the complete absence of correlation in socio-economic status as proof that none of the correlation between the twins' IQs could be attributed to similarities in their home environments... The well known British psychologist Hans J. Eysenck actually claimed that the absence of socio-economic relation between the twins' homes made Burt's study the _only_ one of its kind in which the calculation of heritability had any meaning. Nobel laureate William B. Shockley, the physicist-turned-behaviour geneticist referred to it as 'the best data' on separated twins [(Tucker 1994: 338)](#ref28).

As noted by Tucker [(1994: 338)](#ref28), these prominent scientists had all read Burt's work and had found it flawless.

Cyril Burt died in 1971\. Leon Kamin of Princeton University began soon after to scrutinize his statistical results, and found significant problems in the material. Most significantly, in three different studies with a different number of monozygotic twins, Burt reported correlations of IQ values that were identical to the third decimal place. Such results in real statistical analyses are practically impossible. Kamin ended his investigations by concluding '_the numbers left behind by Professor Burt are simply not worthy of serious scientific attention_' [(Kamin 1973: 11)](#ref22). In 1976 the _Sunday Times_ newspaper published the astonishing information that Burt's two assistants and his co-authors of scientific articles, Margaret Howard and J. Conway, were non-existent persons who were invented by Cyril Burt. These two phantom-experts were authors of several review articles celebrating Burt and attacking his opponents. The articles were published in the _British Journal of Statistical Psychology_ through the fifteen year period that Burt was its editor. Burt's housekeeper admitted to the _Sunday Times_ that she knew that Burt used these pseudonyms ([Gillie 1976](#ref12)). Despite a few attempts to clear Burt of charges of data fabrication and fraud (Joynson 1989; Fletcher 1991), it has been generally accepted since the late 1970s that Burt manipulated and probably falsified those IQ test results that most convincingly supported his theory. [Tucker (1997: 145)](#ref29) concludes that a comparison of Burt's monozygotic twins sample with that from other well documented studies '_leaves little doubt that he committed fraud_'.

It is interesting to note how the prominent scientists that had praised Burt's work now reacted to the findings that Burt had fabricated data and that his work was fraudulent. At first they tried to ignore the accusations and refused to participate in discussions regarding the matter [(Tucker 1994)](#ref28). When the accusations made it to the public sphere, they changed their strategy from complete silence to fierce attacks on the messenger. They tried to argue that because Kamin was a researcher from a different research specialty (animal learning) his investigations were worthless. They called him names like '_a fervent Marxist_' [(Tucker 1994: 340)](#ref28), and accused him of '_some kind of political bias_' [(Tucker 1994: 340)](#ref28).

Harvard psychologist Richard Herrnstein (co-author of a controversial, best-selling book _The Bell Curve_ (Herrnstein and Murray 1994)), was initially outraged when he heard about the accusations against Burt. However, as his work on his Cyril Burt biography progressed, he became aware that Burt had in fact lied. This made him switch position and together with Arthur Jensen he now claimed that they were the two who had discovered Burt's fraud [(Tucker 1994)](#ref28).

The Burt-affair is still debated and is considered among the most important cases of fraud in the history of science. The issue whether intelligence is hereditary or culturally and socio-economically determined is a deep controversy in psychology and related to broader ideological and political views. The common-sense view is that science is not ideological and should contribute _objective_ knowledge to such controversies, but the Burt-case reveals that science may also be ideological (as also indicated by, for example, Habermas, [1970](#ref13)).

The controversy is centred on many fundamental questions. To name a few, it is about how to measure intelligence, it is about whether intelligence is a meaningful concept at all, it is related to theories of cognitive development, it is about the use of correlations, it is about how to identify monozygotic twins in a reliable way, and about what kinds of environments that best stimulate cognitive development. All these questions may be considered one after another, but the answers tend to rest on a package of ideological assumptions. In Denmark, for example, the dominant ideology among psychologists in the 1960s 1970s and early 1980s was the environmentalist view, and many of the assumptions that founded the hereditarian view were challenged by Danish psychologists. Correlation statistics, for example, was substituted with so-called item response theory and educational marks were by some leading psychologists recommended at the expense of intelligence tests (cf., [Jensen _et al._ 1972](#ref20)). Many regarded even the word _intelligence_ itself a fraud. This implies that such a controversy is also somewhat connected to national research traditions.

In the field of sociology, a very different theory of the relation between social class and educational opportunities were put forward by Bernstein ([1971](#ref01)) in his _Class, Codes and Control_:

> Forms of spoken language in the process of their learning initiate, generalize and reinforce special types of relationship with the environment and thus create for the individual particular forms of significance ([Bernstein 1971: 76](#ref01)).

Littlejohn agrees and states, '_people learn their place in the world by virtue of the language codes they employ_' ([Littlejohn 2002: 178](#ref25)).

This means that the same problem is also discussed in the field of sociology. However, the two discourses seem to be rather unconnected. Different theories seem to live relatively independently in different disciplines, each of which is relatively _blind_ for the theories and views advocated by researchers in other disciplines.

What did _confirmation bias_ mean in the Burt case? Most obviously that leading intelligence researchers like Arthur Jensen and Hans J. Eysenck did not discover the many problematic issues in Burt's results. They shared Burt's view on the hereditary nature of intelligence. They were _friends_ in the sense that they had common interests (which may be related to more material interests, for example, by saving psychology from sociology). Whether or not they were also friends in the usual sense is not important here because it is their common interests that explain their bias (or opposite: different interests in this case turned out to be a strong motivation to make a careful check of Burt's results). We have seen that the confirmation bias operates:

1.  Most directly by a lack of critical examination of research claims and research methods (lack of statistical and related checks).
2.  Indirectly by a one-sided orientation in competing theories, conceptions and methods. All this seems to constitute _a packet_ of assumptions.

## How to avoid confirmation bias?

Should bias be avoided? After having read about the Burt case, the answer seems obvious: Yes it should. However, in a way this claim about avoiding bias is related to a positivist claim in which the researchers' subjectivity should be minimized. (Schulz-Hardt, _et al._ ([2000](#ref27)) make clear that in this context the term has a slightly different meaning than in the context of hypothesis testing where the same term is also often used.) We do not believe this is possible or even desirable. We saw above that the packet of assumptions represented a coherent ideology presented as objective science. When researchers are working with real-life issues there are always much more things that needs to be examined than there are available resources to undertake. The ideology of the neutral and objective researcher has problematic implications. First of all it provides the illusion that this view is the only valid one and that we should not search for alternative views. The alternative to the positivist view is the hermeneutical view which admits that the researcher is always influenced by his pre-understanding and that subjectivity cannot and should not be avoided but should be made explicit. Research is then not an accumulation of objective facts but is rather a _dialogue_ between different views and interests. It makes a big difference whether or not this is recognized. Consider, for example, peer review. If researchers are considered _unbiased_, _objective_ and _neutral_ in evaluating research in a given domain, then any qualified researcher might evaluate any manuscript. If, on the other hand, science is considered a dialogue between competing views and interests, then it is important to consider this in selecting referees (and in the editors interpretation of referee assessments).

In some cases, especially in the social sciences, the importance of different views and interests is openly recognized. In Danish economics, for example, there are research institutes (_think tanks_) working from different political points of view (e.g. the Economic Council of the Labour Movement and the liberal Copenhagen Institute). The very existence of such institutions represents recognition of the importance of dialogue between different views.

Where does this leave us regarding source criticism?

> Most people, even most academics, do not have the time, training, or occasion to work through the technical literature on a controversial topic. Instead, they must rely on professionals for a disinterested evaluation” ([Herrnstein 1973: 52](#ref15)).

We clearly have a dilemma here. We should not disregard the scientific literature and just make any opinion as valid as any other. However the idea of a disinterested evaluation of the scientific findings becomes problematic given what we now know about this controversy. Herrnstein ([1973: 53](#ref15)) continues by claiming that the high heritability of IQ '_has doubtless become psychology's best proved, socially significant empirical finding_'. We can see now that the way he relied on '_professionals for a disinterested evaluation_' of the information turned out to be very problematic indeed.

What lessons can be drawn? What advice can be given?

*   Consider the scholarly literature and the scholarly arguments
*   Do not believe too strongly that other people have done their homework. When possible, check for yourself.
*   Consider not just the technical details in the literature, but also the interests at play and the larger theoretical frameworks. When researchers may have some interests, then try to find research from researchers with different interests (including opposite interests).
*   Consider the practical implications of different views. In the end, all knowledge is about practical consequences. That is not to say that science is just political opinions, but that such opinions may causes blindness (and also open eyes).
*   Is the research culture of a strong competitive nature or is it scholarly with deep interests in dialogue and careful examination of alternative views?
*   Consider that scientific technicalities may sometimes be used ideologically to impress people and to provide a relative discredit to alternative views.
*   Do not limit your search to one discipline or one national tradition or one genre. Be aware that the same problem may have been illuminated in other traditions (possibly using different concepts, theoretical frameworks etc).
*   Assume as default that different views and theories exist on any topic, but that the mainstream may be dominant, which is why alternative views often are difficult to locate.
*   Realize that it is difficult to work alone, to check everything on your own. Try to find out which people you trust and consider them allied in the search for truth.
*   Demand of libraries and information systems that they provide services that help to identify the most important arguments from all major points of view.
*   Try to explore a hypothesis consistently over a long period of time. It takes time to identify and consider arguments. Do not constantly shift from one view to the other without deep examination. Clarity is also obtained from failures. We have to work from a set of basic assumptions (a _paradigm_ ([Kuhn 1962](#ref23)) or a _research tradition_ ([Laudan 1977](#ref24))).

## Conclusion

Source criticism is, among other things, also about trust between people and thus implies social psychological relations. As we have seen in this paper, we can learn about relevant issues in the discipline of social psychology, but we may also learn about social psychology in the history of science (and from other sources, including fiction). As we have seen, it may be problematic only to consider the points of view expressed in one discipline. This is itself an important lesson in relation to source criticism.

Social psychology has provided an empirical _law_ about confirmation bias. The real-life study of the Burt-affair has, however, provided a better understanding of the dynamics of this phenomenon. We saw, for example, that some researchers did change their views when it was in their personal interest to do so. The experiments in social psychology were more in line with positivist ideals of science, whereas the study of the Burt case and the interpretation of its consequences is more in line with the ideals of hermeneutics. We find that this paper shows the importance of the hermeneutical approach.

We have thus demonstrated the importance of considering knowledge claims in the broader social context and as potentially _biased_ by different views and interests. The best way to _avoid bias_ is to learn about the arguments that are being put forward from different views. To help people doing so should be the most important function of libraries and information systems.

## About the authors

Birger Hjørland is Professor at the Royal School of Library and Information Science, Denmark (RSLIS). He recieved his MA in psychology at the university of Copenhagen 1974 and his PhD in Library and Information Science at the University of Gothenburg, Sweden in 1993\. He can be contacted at [bh@iva.dk<mailto:bh@iva.dk></mailto:bh@iva.dk>](mailto: bh@iva.dk <mailto:bh@iva.dk> )

Jeppe Nicolaisen is Associate Professor at the Royal School of Library and Information Science, Denmark (RSLIS) and Visiting Professor at Uppsala University, Sweden (Institution of ALM). He received his bachelor and master degrees as well as his PhD from RSLIS. He can be contacted at: [jni@iva.dk<mailto:jni@iva.dk></mailto:jni@iva.dk>](mailto:jni@iva.dk <mailto:jni@iva.dk> )

*   Bacon, F. (1620, 1960). _The New Organon and related writings_. New York, NY: Liberal Arts Press.
*   Bernstein, B. (1971). _Class, codes and control._ (Volume 1). London: Routledge & Kegan Paul.
*   Brunsson, N. (1982). The irrationality of action and action rationality: decisions, ideologies and organizational actions. _Journal of Management Studies_, **19**(1), 29-44.
*   Cotton, J.L. (1985). Cognitive dissonance in selective exposure. In: D. Zillmann & J. Bryant (Eds.), _Selective exposure to communication_ (pp. 11-33). Hillsdale, NJ: Erlbaum.
*   Eagly, A.H. & Chaiken, S. (1993). _The psychology of attitudes_. Fort Worth, TX: Harcourt Brace Jovanovich.
*   Eagly, A.H. & Chaiken, S. (1998). Attitude structure and function. In: D.T. Gilbert, S.T. Fiske, & G. Lindzey (Eds.), _The handbook of social psychology_. 4th ed., Vol. 1 (pp. 269-322). New York, NY: McGraw-Hill.
*   Eagly, A.H. & Chaiken, S. (2005). Attitude research in the 21st century: the current state of knowledge. In D. Albarraccin, B.T. Johnson & M.P. Zanna (Eds.), _The handbook of attitudes_. (pp. 743-767). Mahwah, NJ: Erlbaum.
*   Festinger, L. (1957). _A theory of cognitive dissonance_. Stanford, CA: Stanford University Press.
*   Festinger, L. (1964). _Conflict, decision, and dissonance_. Stanford, CA: Stanford University Press.
*   Fletcher, R. (1991). _Science, ideology and the media: the Cyril Burt scandal._ New Brunswick, NJ: Transaction Publishers.
*   Freedman, J.L. & Sears, D.O. (1965). Selective exposure. _Advances in experimental social psychology_, **2**, 57-97.
*   Frey, D. (1986). Recent research on selective exposure to information. _Advances in Experimental Social Psychology_, **19**, 41-80.
*   Gillie, O. (1976, October 24). Crucial data was faked by eminent psychologist. _Sunday Times_, p.1.
*   Habermas, J. (1970). Technology and science as 'ideology'. In J. Habermas _Toward a rational society_. J. Shapiro (trans.) Boston, MA: Beacon Press.
*   Hart, W., Eagly, A.H., Lindberg, M.J., Albarraccin, D., Brechan, I. & Merrill, L. (2009). Feeling validated versus being correct: a meta-analysis of selective exposure to information. _Psychological Bulletin_, **135**(4): 555-588.
*   Herrnstein, R.J. (1973). _I.Q. in the meritocracy_. Boston, MA: Atlantic Monthly Press.
*   Herrnstein, R. & Murray, C. (1994). _The bell curve: intelligence and class structure in american life_. New York, NY: Free Press.
*   James, W. (1890). _Principles of psychology_. New York, NY: Holt.
*   Janis, I.L. (1982). _Groupthink_. Boston, MA: Houghton Mifflin.
*   Jensen, J. & Jensen, J.A. & Nissen, T. (1972). _Egnethed og uddannelse: egenskabsbegrebet i paedagogisk-psykologisk belysning._ [Qualifications and education: the concept of qualification in a pedagogical-psychological perspective.] Copenhagen: Munksgaard.
*   Joynson, R.B. (1989). _The Burt affair_. London: Routledge.
*   Kamin, L.J. (1973). _Heredity, intelligence, politics, and psychology._ Invited address presented at the annual meeting of the Eastern Psychological Association, Washington, DC, April 1973.
*   Kuhn, T.S. (1962). _The structure of scientific revolutions_. Chicago, IL: University of Chicago Press.
*   Laudan, L. (1977). _Progress and its problems: toward a theory of scientific growth_. Berkeley, CA: University of California Press.
*   Littlejohn, S. (2002). _Theories of human communication._ Albuquerque, NM: Wadsworth.
*   Nemeth, C.J. & Rogers, J. (1996). Dissent and the search for information. _British Journal of Social Psychology_, **35**(1), 67-76.
*   [Source criticism](http://en.wikipedia.org/wiki/Source_criticism). (2008). In _Wikipedia. The free encyclopedia._ Retrieved July 15, 2009 from http://en.wikipedia.org/wiki/Source%5Fcriticism.
*   Schulz-Hardt, S., Frey, D., L¸thgens, C. & Moscovici, S. (2000). Biased information search in group decision making. _Journal of Personality and Social Psychology_, **78**(4), 655-669.
*   Tucker, W.H. (1994). Fact and fiction in the discovery of Sir Cyril Burt's flaws. _Journal of the History of the Behavioral Sciences_, **30**(4), 335-347.
*   Tucker, W.H. (1997). Re-reconsidering Burt: beyond a reasonable doubt. Journal of the _History of the Behavioral Sciences_, **33**(2), 145-162.