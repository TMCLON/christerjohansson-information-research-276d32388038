<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"> 
<html xmlns="http://www.w3.org/1999/xhtml"> 
<head> 
<title>Transferring evidence into practice: what evidence summaries of library and information studies research tell practitioners</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" /> 
<link href="../IRstyle2.css" rel="stylesheet" media="screen" title="serif" /> 
<link rel="alternate stylesheet" type="text/css" media="screen" title="sans" href="http://www.informationr.net/ir//IRstylesans.css" /> 
<link rev="made" href="mailto:t.d.wilson@shef.ac.uk" /> 
 
<!--Enter appropriate data in the content fields--> 
<meta name="dc.title" content="Transferring evidence into practice: what evidence summaries of library and information studies research tell practitioners" /> 
<meta name="dc.creator" content="Lorie A. Kloda, Denise Koufogiannakis, Katrine Mallan" /> 
<meta name="dc.subject" content="Give a brief description of your paper" /> 
<meta name="dc.description" content="Critical appraisal is a crucial aspect of evidence-based practice. In order to determine whether research is valid, reliable and applicable, the evidence-based practice process advocates that published research be critically appraised. Between 2006 and 2008, the journal Evidence Based Library and Information Practice published 101 evidence summaries, critically appraising research in library and information studies. These evidence summaries can be examined in order to determine common strengths and weaknesses of research relevant to library and information studies and identify commonalities in existing evidence summary commentaries. We undertook a directed qualitative content analysis of the commentary portion of all 101 evidence summaries published in the journal, Evidence Based Library and Information Practice from 2006-2008. Evidence summaries reveal more weaknesses than strengths in the library and information studies research. In general, evidence summary writers tend to remark on weaknesses relating to validity and reliability, yet paradoxically point out strengths with respect to research's applicability to practice. Further research is required to understand why evidence summary writers note more weaknesses than strengths in library and information studies research and whether this reflects the actual quality of the research in general.
" /> 
<meta name="dc.subject.keywords" content="information dissemination, content analysis, evidence-based practice, librarianship, critical appraisal" /> 
 
<!--leave the following to be completed by the Editor--> 
<meta name="robots" content="all" /> 

<meta name="dc.publisher" content="Professor T.D. Wilson" /> 
<meta name="dc.coverage.placename" content="global" /> 
<meta name="dc.type" content="text" /> 
<meta name="dc.identifier" scheme="ISSN" content="1368-1613" /> 
<meta name="dc.identifier" scheme="URI" content="http://InformationR.net/ir/16-1/paper465.html" /> 
<meta name="dc.relation.IsPartOf" content="http://InformationR.net/ir/16-1/infres161.html" /> 
<meta name="dc.format" content="text/html" /> 
<meta name="dc.language" content="en" /> 
<meta name="dc.rights" content="http://creativecommons.org/licenses/by-nd-nc/1.0/" /> 
<meta name="dc.date.available" content="2011-03-15" /> 
 
<script language="javascript" type="text/javascript"> 
 
		var flag;
		flag = true;
		function doChangeFont()
		{
			if (flag)
			{
			var htmlDoc = document.getElementsByTagName('head').item(0);
			var css = document.createElement('link');
			css.setAttribute('rel', 'stylesheet');
			css.setAttribute('type', 'text/css');
			css.setAttribute('href', '../sans.css');
			htmlDoc.appendChild(css);
			flag = false;
			} 
			else
			{
			var htmlDoc = document.getElementsByTagName('head').item(0);
			var css = document.createElement('link');
			css.setAttribute('rel', 'stylesheet');
			css.setAttribute('type', 'text/css');
			css.setAttribute('href', '../IRstyle2.css');
			htmlDoc.appendChild(css);
			flag = true;
			}	
		}
		
	</script> 
	
<style type="text/css"> 
.button {
	width: 45em;
	padding: 0 0 0 0;
	font-family: Verdana, Lucida, Geneva, Helvetica, Arial, sans-serif;
	font-size: small;
	font-weight: bold;  
	background-color: #ffffff;
	color: #000000;
	display: inline;
	text-align: center;
	}
		
 
.button ul {
		list-style: none;
		margin: 0;
		padding: 0;
		border: none;
		display: inline;
		}
		
.button li {
		margin: 0;
		font-family: Verdana, Lucida, Geneva, Helvetica, Arial, sans-serif;
	    font-size: small;
	    font-weight: bold;  
		background-color: #fff000<!-- #2175bc; --> 
		color: #000000;
		text-decoration: none;
		display: inline;
		}
 
.button li a:hover {
		background-color: azure;
		color: #ff0000;
		width: auto;
		}
		
fieldset {
    padding: .5em;
    background: white;
    border: 1px dotted #5E96FD;
    margin-left: 15px;
    margin-right: 15px;
    margin-top: .5em;
	}
 
legend {
    color: white;
    background-color: #5E96FD;
    font-size: medium;
    padding: .1ex .5ex;
    border-right: 1px solid navy;
    border-bottom: 1px solid navy;
    font-weight: bold;
}
 
 
</style> 
 
</head> 
<body bgcolor="#ffffff"> 
<table cellspacing="0" cellpadding="0" align="center" border="0">
  <tbody>
  <tr>
    <td align="center" colspan="5" height="30"><img height="45" alt="header" src="http://www.informationr.net/ir//mini_logo2.gif" 
      width="336" /><br /><span style="font-size: medium; font-variant: small-caps; font-weight: bold;">vol. 16  no. 1, March, 2011</span><br /><br />
      <div class="button">
      <ul>
        <li><a href="infres161.html">Contents</a> |  </li>
        <li><a href="http://www.informationr.net/ir//iraindex.html">Author index</a> |  </li>
        <li><a href="../irsindex.html">Subject index</a> |  </li>
        <li><a href="../search.html">Search</a> |  </li>
        <li><a href="../index.html">Home</a>  </li>
   </ul></div></td></tr>
  <tr>
    <td>&nbsp;</td></tr></tbody></table>
	
<hr style="COLOR: #5E96FD" size="1" /> 
 
<h1>Transferring evidence into practice: what evidence summaries of library and information studies research tell practitioners</h1> 
<br /> 

<div style="margin-left: 10%; margin-right: 10%;"> 
<h4><a href="paper465.html#authors">Lorie A. Kloda</a><br /> 
McGill University, Life Sciences Library, 3655 Promenade Sir William Osler, Montreal, Quebec, Canada, H3G 1Y6<br /> 
<a href="paper465.html#authors">Denise Koufogiannakis</a><br /> 
University of Alberta, 5-25 Cameron Library, Edmonton, Alberta, Canada, T6G 2J8<br /> 
<a href="paper465.html#authors">Katrine Mallan</a><br /> 
Jacobs University &ndash; IRC, Campus Ring 1, 28759 Bremen, Germany </h4> 
</div> 
<br /> 
 
<form action="paper465.html"> 
<fieldset> 
<legend>Abstract </legend> 
<blockquote><strong>Introduction.</strong> Critical appraisal is a crucial aspect of evidence-based practice. In order to determine whether research is valid, reliable and applicable, the evidence-based practice process advocates that published research be critically appraised. Between 2006 and 2008, the journal <em>Evidence Based Library and Information Practice</em> published 101 evidence summaries, critically appraising research in library and information studies. These evidence summaries can be examined in order to determine common strengths and weaknesses of research relevant to library and information studies and identify commonalities in existing evidence summary commentaries.<br />  
<strong>Method.</strong> We undertook a directed qualitative content analysis of the commentary portion of all 101 evidence summaries published in the journal, <em>Evidence Based Library and Information Practice</em> from 2006-2008.<br />  
<strong>Findings.</strong> Evidence summaries reveal more weaknesses than strengths in the library and information studies research. In general, evidence summary writers tend to remark on weaknesses relating to validity and reliability, yet paradoxically point out strengths with respect to research's applicability to practice.<br />  
<strong>Conclusions.</strong>Further research is required to understand why evidence summary writers note more weaknesses than strengths in library and information studies research and whether this reflects the actual quality of the research in general.</blockquote> 
</fieldset> 
</form> 
 
<br /> 
<div align="center"> 
<input type="button" value="change font" class="btn" style="font-variant: small-caps; font-weight: bold; font-family: Verdana; color: white; background-color: #5E96FD;" onclick="doChangeFont()" /></div> 

<br /> 
 
<h2>Introduction</h2> 
 
<p>Critical appraisal is a crucial aspect of evidence-based practice. In order to determine whether research is valid, reliable and applicable, the evidence-based practice process advocates that published research be critically appraised. Critical appraisal in library and information studies is seldom published, but since 2006, the journal <em>Evidence Based Library and Information Practice</em> has published an average of eight evidence summaries in each issue. Evidence summaries provide a synopsis and critical appraisal of published research in order to facilitate the transfer of research into practice. This study aims to determine strengths and weaknesses of library and information studies research, as identified in the journal's evidence summaries, so that as a profession we might improve our research, and as readers we may consider the strengths and weaknesses of research publications as well as their utility.</p>

 
<h2>Background</h2>

<h3>Evidence-based practice in library and information studies </h3>

<p>Evidence-based practice in library and information studies is, </p>

<blockquote>an approach to information science that promotes the collection, interpretation and integration of valid, important and applicable user-reported, librarian-observed, and research-derived evidence. The best available evidence, moderated by user needs and preferences, is applied to improve the quality of professional judgments (<a href="paper465.html#boo00">Booth 2000</a>).</blockquote> 

<p>This definition stresses three main areas that contribute to evidence-based practice: 1) research evidence; 2) user needs and preferences; 3) professional judgments. All three of these components are vital to evidence-based practice.  Research is not conducted in isolation, but rather, is integrated with our professional judgment and within our local context. </p>

<p>The recognized steps in evidence-based practice are: </p>

<blockquote>
<ol>
<li><em>Ask</em> a focused question </li>
<li><em>Acquire</em> evidence on the topic </li>
<li><em>Appraise</em> the research studies</li>
<li><em>Apply</em> the findings</li>
<li><em>Assess</em> the impact (<a href="paper465.html#daw05">Dawes <em>et al</em>. 2005</a>).</li>
</ol>
</blockquote>


<p>The third step, <em>appraise</em>, refers to the critical appraisal of original research in order to determine its validity, reliability and applicability. Appraisal is a rather onerous task, requiring expertise in a myriad of research methods depending on the study's research design. It is this step that the evidence summaries published in the journal <em>Evidence Based Library and Information Practice</em> attempt to accomplish, saving the practitioners who read them time and providing them with the benefit of others' expertise. </p>

<p><em><a href="http://ejournals.library.ualberta.ca/index.php/EBLIP">Evidence Based Library and Information Practice</a></em> is an open access journal featuring original research articles, evidence summaries, and commentaries. The journal is available entirely online and is hosted by the University of Alberta using the Open Journal Systems platform, part of the <a href="http://pkp.sfu.ca/?q=ojs">Public Knowledge Project</a>. It reaches an international audience and as of 2009, has over 2000 registered readers. The journal launched in January 2006, with issues published quarterly. <em>Evidence Based Library and Information Practice</em> is the only current library and information studies journal that publishes evidence summaries.</p>

<h3>Evidence summaries</h3>

<p>The evidence summaries published in <em>Evidence Based Library and Information Practice</em> are modelled on synopses found in health sciences journals such as <em>ACP Journal Club, Evidence Based Nursing</em> and POEMs (patient-oriented evidence that matters) in <em>Essential Evidence Plus</em>. In these publications, clinicians can read structured abstracts of clinical research with commentaries, and sometimes a <em>bottom line</em>: a statement that answers the question: What does this change (or not change) in my practice?</p>

<p>Each evidence summary in the journal consists of a structured abstract summarizing the original research article as well as a commentary of 300 to 400 words appraising the quality of the research. Approximately eight evidence summaries are published in every issue, summarizing research in all areas of librarianship. The previously published research that undergoes appraisal is culled from reputable peer reviewed journals, mainly in library and information studies, and occasionally in related fields. The Associate Editor for Evidence Summaries regularly reviews approximately ninety journals that publish peer reviewed research articles, and chooses research articles that appear relevant for library and information studies practitioners. The topics and research settings are chosen in order to appeal to a wide ranging readership. </p>

<p>Evidence summaries are written by a team of writers selected by the Associate Editor on a rotational basis, each normally writing four evidence summaries within a two-year period. Team members apply to be on the team, and are selected by the Editorial Team based on their areas of expertise and their experience with evidence-based practice and critical appraisal skills. Evidence summary writers must follow established guidelines (Appendix A) detailing what should be included in an evidence summary, and are encouraged to use existing critical appraisal tools to aid them in their appraisal. Each evidence summary submitted by a member of the team goes through the journal's regular double-blind peer review process with at least two peer reviewers providing feedback before the submission is considered for acceptance by the Associate Editor.</p> 

<p>The structured abstract of the evidence summary allows practitioners to obtain the essential elements of the study without having to read the original, while the commentary portion offers an evaluation of its quality and usefulness. The commentary provides the evidence summary writer with the chance to comment on the original study's method, the reporting, the research's significance within librarianship and, more importantly, how the research may impact professional practice. </p>

<p>Although several publications and electronic resources in the health sciences publish critical appraisals of original research, we were unable to find any published reports of research analysing their content. Several studies have investigated the use of evidence summaries for impact on knowledge and practice (e.g., <a href="paper465.html#gra08">Grad <em>et al.</em> 2008</a>) but these focused on practitioners' (in this case, health professionals') perceptions. </p>

<h2>Purpose and objectives </h2>

<p>The purpose of this research study was to identify criticisms, both positive and negative, of the library and information studies research literature. The study's objectives were twofold:</p> 

<ol><li>To determine the strengths and weaknesses identified by appraisers of research relevant to library and information studies, as reported in the commentary section of published evidence summaries, and;</li> 
<li>To identify commonalities within evidence summary commentaries published to date.</li> </ol>


<h2>Methods</h2>

<p>We undertook a directed qualitative content analysis of the commentary portion of evidence summaries published in <em>Evidence Based Library and Information Practice</em> from 2006-2008. '<em>Qualitative content analysis goes beyond merely counting words or extracting objective content from text to examine meanings, themes, and patterns that may be manifest or latent in a particular text</em>' (<a href="paper465.html#zha09">Zhang and Wildemuth 2009</a>: 309). In this way, we were able to identify the nature of the criticisms described in the evidence summaries and the tone (positive, negative, neutral) of these statements. The emphasis was not on frequencies, but on the importance placed on certain characteristics, and on uncovering new aspects of research considered important by the evidence summary writers. </p>

<p>All twelve issues of the journal were included, for a total of 101 evidence summaries. A data extraction form was created based upon evidence summary guidelines for writers along with elements relating to validity, reliability and applicability from critical appraisal worksheets such as CriSTAL (<a href="paper465.html#boo03">Booth and Brice 2003</a>), RELIANT (<a href="paper465.html#kou06">Koufogiannakis <em>et al.</em> 2006</a>) and the critical appraisal tool created by Glynn (<a href="paper465.html#gly06">2006</a>). The data extraction form (<a href="paper465.html#appb">Appendix B</a>) was designed to facilitate both inductive and deductive analysis. The form went through two rounds of pre-testing, whereby all three researchers independently coded and compared results. Researchers discussed areas of confusion or omission, refining the extraction tool until we felt confident that the form was clear and straightforward.</p>

<p>Each commentary was read through and scrutinized independently by two of the researchers after which any discrepancies were resolved by the third researcher. Additionally, we looked for possible emerging categories, that is, new concepts that arose from our reading of the evidence summaries during the analysis but that were not already accounted for in our data extraction form. We kept track of these new categories as well. </p>

<p>The data extraction form focused on areas of validity, reliability and applicability. While these terms might seem to reflect a quantitative or positivist approach, the criteria were also applicable for research employing interpretive, qualitative inquiry.</p>

<p>The data extraction form examined five areas that indicate validity. Validity is '<em>the extent to which the results of the research are likely to be free from bias</em>' (<a href="paper465.html#rey00">Reynolds 2000</a>: 25). In the commentary portion of each evidence summary, we looked to see if the evidence summary writer noted: </p>

<ol>
    <li>the presence of a focused issue or research question;</li>
    <li>the possibility of any conflict of interest;</li>
    <li>the suitability and replicability of the research method;</li>
    <li>the suitability of the population and the sampling method;</li>
    <li>the data collection instrument&rsquo;s validity.</li>
</ol>

<p>For each of these, we coded for whether the writer noted these elements as strengths of the original study, weaknesses, or if the element was described neutrally. While it was possible for the same element to be coded both as a strength and a weakness: this was rare.   </p>

<p>Seven areas touching on reliability were also examined. Reliability is '<em>the likelihood that this study reports something that is reproducible, as opposed to being a &quot;fluke&quot; or chance result</em>' (<a href="paper465.html#boo04">Booth and Brice 2004</a>: 105). We looked to see if the evidence summary writer noted:</p> 

<ol>
    <li>the clarity of results;</li>
    <li>the response rate;</li>
    <li>the utility and clarity of the analysis;</li>
    <li>the compatibility of the analysis to the research design;</li>
    <li>whether or not the study results addressed the original research question;</li>
    <li>the limitations of the study; and</li>
    <li>whether the conclusions were warranted (i.e., based on actual results of the study).</li>
</ol>

<p>Finally, we coded for three aspects relating to applicability, '<em>the extent to which the results are likely to impact on practice</em>' (<a href="paper465.html#boo04">Booth and Brice 2004</a>: 105). We looked to see if the evidence summary writer noted:</p>

<ol>
    <li>the implications for practice reported in the original study;</li>
    <li>the applicability to populations beyond those investigated in the original study; and</li>
    <li>any local information required to implement the research results.</li>
</ol>

<h2>Findings</h2>

<h3>General attributes</h3>

<p>To put the evidence summaries into context we noted some general attributes of the 101 summaries we examined, by grouping them by aspects such as domain, setting, source, and length. </p>

<p>In evidence-based library and information studies, domains are used to assist with identifying the most applicable resources to search for evidence and to focus a given question. Based on the research of Koufogiannakis, Slater and Crumley (<a href="paper465.html#kou04">2004</a>), there are six domains into which research literature can generally be grouped. </p>

<p>The evidence summaries were generally representative of the breadth of domains represented, with most articles appraised falling in the categories of <em>information access and retrieval</em> or <em>collections</em> (see Table 1). Domains are not mutually exclusive, so an article may belong to more than one domain.</p>

<table width="30%" border="1" cellspacing="0" cellpadding="3" align="center" style="border-right: #99f5fb solid; border-top: #99f5fb solid; font-size: smaller; border-left: #99f5fb solid; border-bottom: #99f5fb solid; font-style: normal; font-family: verdana, geneva, arial, helvetica, sans-serif; background-color: #fdffdd"> 
<caption align="bottom"><br /><strong>Table 1: Evidence summaries by domain</strong><br /></caption> 
<tr>
  <td>Information access and retrieval</td> <td>26</td>
</tr>
<tr>
  <td>Collections</td> <td>25</td>
</tr>
<tr>
  <td>Education</td> <td>21</td>
</tr>
<tr>
  <td>Management</td> <td>16</td>
</tr>
<tr>
  <td>Reference</td> <td>14</td>
</tr>
<tr>
  <td>Professional issues</td> <td>12</td>
</tr>
</table>
 
 <p>The setting for the research was also noted, and is represented in Table 2. The highest number of research articles that were critically appraised in an evidence summary came from academic settings. Again, the setting within which research takes place is not necessarily mutually exclusive, as research could be in both a health and academic setting, for example.</p>
 
 <table width="30%" border="1" cellspacing="0" cellpadding="3" align="center" style="border-right: #99f5fb solid; border-top: #99f5fb solid; font-size: smaller; border-left: #99f5fb solid; border-bottom: #99f5fb solid; font-style: normal; font-family: verdana, geneva, arial, helvetica, sans-serif; background-color: #fdffdd"> 
<caption align="bottom"><br /><strong>Table 2: Evidence summaries by setting</strong><br /></caption> 
<tr>
  <td>Academic</td> <td>45</td>
</tr>
<tr>
  <td>Health</td> <td>27</td>
</tr>
<tr>
  <td>Public</td> <td>12</td>
</tr>
<tr>
  <td>School</td> <td>8</td>
</tr>
<tr>
  <td>Any and/or All</td> <td>7</td>
</tr>
<tr>
  <td>Scholarly publishing</td> <td>6</td>
</tr>
<tr>
  <td>Special</td> <td>2</td>
</tr>
</table>

<p>Commentaries within evidence summaries are supposed to be between 300 and 400 words. We tabulated word counts for the 101 commentaries included in this study and found that the mean length of commentaries was 517 words. These range between 140 and 1220 words, and the majority of commentaries (n=39) were between 400 and 499 words. </p>

<h3>Validity</h3>

<p>For the validity aspect of the evidence summaries, the analysis revealed some trends. Elements of validity that were most commonly referred to by the evidence summary writers were: '<em>the suitability of the population and the sampling method</em>' (n=80) and '<em>the suitability and replicability of the research method</em>' (n=76). In both cases, more than two-thirds of the time, these were identified by the evidence summary writers as <em>weaknesses</em> of the original research. An example of a comment regarding a weak choice of method: '<em>one wonders if there are other variables in the studies that may have also had an impact on the study results</em>'. Similarly, for the suitability of the population, another evidence summary writer commented, '<em>Participants were randomly contacted but it is unclear how randomization was done or whether there was a self-selection bias in the type of respondent who agreed to participate (response rates were not provided)</em>'. </p>

<p>The only category relating to validity that was commonly viewed as a strength was '<em>the presence of a focused issue or research question</em>'. This was referred to a total of fifty-one times, most commonly (n=24) as a strength of the original study. An example of a comment in the evidence summary that was coded as a strength is, '<em>The aims of the study were clear</em>'. This variable was noted as a weakness eight times, and for the remainder, comments were neutral.</p>

<p>The other two aspects of validity were less often mentioned by the evidence summary writers. '<em>the data collection instrument's validity</em>' was mentioned in thirty-eight of the evidence summaries and as a weakness on nineteen occasions, while '<em>the possibility of any conflict of interest</em>' was mentioned in merely ten (and as a weakness, for seven of these).</p>

<h3>Reliability</h3>

<p>We coded for the seven areas relating to reliability. For all seven areas, these elements were noted by the evidence summary writers as weaknesses of the original research. In general, reliability was not an area very heavily noted by the evidence summary writers. The area most commonly noted (n=57) was '<em>limitations of the study</em>', with the majority of these limitations (n=33) being looked upon negatively. Only in three did evidence summary writers remark on this issue as strength, and twenty-three were neutral in their appraisal. '<em>The utility and clarity of the analysis</em>' was noted in forty-one evidence summaries, mostly as a weakness (n=26), and '<em>the compatibility of the analysis to the research design</em>' was also seen as a weakness in the research being appraised (n=32 out of 37 mentions). We present an illustrative comment from one evidence summary discussing the utility of analysis method:</p>

<blockquote><em>The study reports several statistically significant results in relation to the research questions, yet the analyses seem misinterpreted. For example, self-efficacy and use of electronic information jointly contributed 9% of the variance of academic performance. A large amount of variance and thus other contributing factors (91%) remain unaccounted. Both the R2 and the adjusted R2 (0.05531) indicate that these data do not represent a good statistical model.</em></blockquote>

<p>The other areas related to reliability were remarked upon much less by evidence summary writers, but when they were noted, were generally presented as weaknesses of the original study. </p>

<h3>Applicability</h3>

<p>In contrast to aspects of validity and reliability, applicability was an area many evidence summary writers noted as a <em>strength</em> of the original research articles. Most commonly noted in the commentary section were '<em>the implications for practice reported in the original study</em>' (n=70) with forty-five studies noted as having this as a strength. Some reported the applicability as weakness of the study (n=14) or neutrally (n=10). The other two areas, '<em>applicability to populations beyond those investigated in the original study</em>' and '<em>any local information required to implement the research results</em>' were mentioned less frequently, but positively. An example of a positive comment by one evidence summary writer was: '<em>suggests that Web-based tutorials are at least as effective as face to face teaching sessions and that these may be successfully delivered either in the classroom or via the Web</em>'. Occasionally, the writer noted applicability of the study as a weakness, for example, '<em>it is not immediately clear how this information could be utilized by library practitioners</em>'.</p>

<h3>Other findings of note</h3>

<p>As part of the content analysis, we coded for other elements beyond validity, reliability and applicability.  First, we verified if the evidence summary writer situated the research article they were appraising within a wider context. Forty-eight of the 101 summaries did situate the research they were appraising within a wider context, either commenting on research in this area in general, noting societal or political aspects affecting the topic, or directly citing relevant research (n=30).  In addition, fifty-seven out of the 101 evidence summaries made statements noting the overall significance of the original research to library and information studies. </p>
            
<p>One category that emerged from the content analysis was the quality of the literature review. Eleven commentaries included a statement about the literature review's contribution to the research, with seven evidence summaries noting the literature as a strength, three as a weakness, and one neutrally. For example, one evidence summary writer noted,</p>

<blockquote>What is perhaps more valuable in this paper is the extensive use of the research literature to inform the various ideas throughout. The literature reviewis robust, and the author includes results from previous studies all though the paper to strengthen his statements and conclusions. </blockquote>  
  
<p>Another emerging category dealt with ethical issues. In one evidence summary the lack of participant consent was noted, and in another the original article was noted as a duplicate publication. These two examples point to weaknesses in research that readers should be aware of and that impact the value of research results. One evidence summary writer consistently cited the critical appraisal tool that was employed in writing the evidence summaries. </p>

<p>Finally, for each evidence summary, the length of the commentary section and corresponding number of categories were calculated to determine if there might be a relationship between the length of the commentary and the number of elements noted. No relationship was apparent, that is, evidence summary commentaries that were longer did not contain more elements of appraisal than those that were brief. The average number of categories discussed in an evidence summary commentary was 7.8 (range between 4 and 14 elements noted).  </p>

<h2>Discussion of findings</h2>

<p>This research has several limitations. Firstly, while we decided to include all evidence summaries from the journal <em>Evidence Based Library and Information Practice</em>, there were 101 summaries, written by twenty-eight different writers, some writing up to six or seven within the three year period. This may have led to findings that may not be as applicable to those evidence summaries published since 2008, as the team has changed over time. </p>

<p>The evidence summaries included appraisal of articles that were selected mainly by the Associate Editor at the time, and were not randomly selected from the library and information studies literature. Findings from this research are therefore not representative of strengths and weaknesses of the library and information studies literature as a whole, but reflect the emphasis placed on the selected research publications by the evidence summary writing team. As other scholarly publications begin to produce evidence summaries, and more writers create them, more variability among summaries may appear. The evidence summary writers from this journal may exhibit similar biases and preferences that may have skewed our findings.  In addition, despite the structured element of evidence summaries, the writing style of authors varied greatly, thus making the content analysis difficult in some cases. For example, one writer might be clearly pointing out a study's weakness, while another might be more indirect. This results in difficulties in the analysis. This might explain why, in several cases, we had to judge a term as neutral. Perhaps the writer thought their statement was obviously negative, but if it was not overt, it was coded as neutral.  </p>

<p>One of the researchers (LK) was also an evidence summary writer, and contributed six publications to the set of 101. Potential bias was avoided by assigning the other two researchers to analyse these documents, and allowed them to resolve any disagreements. </p>

<p>We believe this analysis will provide insights for library and information studies professionals regarding aspects of validity, reliability and applicability that should be considered when conducting or reading research. The analysis highlights several areas where overt weaknesses were noted by the evidence summary writers. These areas of weakness are ones that those conducting research should be aware of and proactively address when conducting their research and reporting results, hence strengthening the body of research within our field. While no research is perfect, being aware of weaknesses and potential pitfalls should help library and information studies professionals address these elements in their own research endeavours. Likewise, noted areas of strength provide examples of good practice that new researchers can model.</p>

<p>This study also raised many new questions related to critical appraisal and library and information studies research. Aspects of validity and reliability in studies that were critically appraised in <em>Evidence Based Library and Information Practice</em> were more often noted as weaknesses of the study. Whether this was due to general poor study design or the focus of the writer in trying to point out faults rather than positives, is unknown. A follow-up to this research could be to interview those who write evidence summaries to determine their goals and motivations, and the degree to which they note negative and positive aspects of previously published research. As well, we were left to wonder what we could conclude from areas that were not noted very frequently by the evidence summary writers. Are these areas not of concern because they were dealt with appropriately by the original author, not important enough to mention, or simply overlooked?</p>

<p>Finally, despite the evidence summary writers' overall negative view towards elements relating to validity and reliability, applicability was still widely viewed as positive: Why? It seems logical that if validity and reliability are weak in a study, that study's applicability would therefore be weak as well. Is there a lack of connection between the parts of a paper? Were the evidence summary writers focused on weaknesses that put findings into question (validity and reliability) and not as concerned with aspects of applicability, or were they trying to end their appraisal on a positive note as generally applicability is discussed last in the commentary? Alternatively, the research articles may have yielded elements that were relevant to practice, even if the actual results came from weak methodology. These questions could be looked at more closely by subsequent research that combined interviews of the evidence summary writers with closer inspection of the text within a paper, using a sample of the total summaries.</p>

<p>We also suggest that further study investigating library and information studies practitioners' perceptions of evidence summaries and their impact on knowledge and practice would be an important contribution to this area of research. Doing similar work to what was done in medicine by <a href="paper465.html#gra08">Grad <em>et al</em></a>. with their information impact scale would relay a sense of the importance of the evidence summaries to practitioners who wish to integrate research into their learning and decision making. </p>


<h2>Conclusion</h2>

<p>This study shows that evidence summaries published in <em>Evidence Based Library and Information Practice</em> between 2006 and 2008 reveal more weaknesses than strengths in the library and information studies research that was critically appraised. In general, evidence summary writers tend to remark on weaknesses in reports of research relating to validity and reliability, yet paradoxically point out strengths with respect to their applicability to practice. The exact reasons for this require further qualitative research, to reach a more complete understanding of the reasons why the results were as noted.</p>

<p>These results have implications for the future of evidence summaries published in <em>Evidence Based Library and Information Practice</em>. The Editorial Team will need to consider revisions to evidence summary guidelines, possibly adding more structure to the commentary section, and adding elements such as comment on the literature review and what critical appraisal tool was used, a better balance between strengths and weaknesses, and stricter adherence to word length. The Editorial Team has already implemented a checklist of items to consider for peer reviewers containing more detailed directions on what they should be looking for and commenting on in respect to their review of the evidence summary. They have also implemented an application procedure for new evidence summary writers that includes writing a sample evidence summary before they joined the team. </p>

<h2>Acknowledgements</h2> 
 
<p>This paper is based on presentations given at the 5th International Evidence Based Library and Information Practice Conference in Stockholm, Sweden (June 30 to July 3, 2009) and the Workshop on Instruction in Library Use in Montreal, Canada (May 25 to 27, 2009).</p> 
 
<h2 id="authors">About the authors</h2> 
 
<p>Lorie Kloda is an Associate Librarian in the Life Sciences Library at McGill University and a doctoral candidate at the School of Information Studies. She may be contacted at <a href="mailto:lorie.kloda@mcgill.ca">lorie.kloda@mcgill.ca</a><br />

Denise Koufogiannakis is Collections and Acquisitions Coordinator at the University of Alberta Libraries, Edmonton, Alberta, Canada. She received her Master of Library and Information Studies degree from the University of Alberta, and is currently working on a PhD in Information Studies at Aberystwyth University, UK. She can be contacted at: <a href="mailto:denise.koufogiannakis@Ualberta.ca">denise.koufogiannakis@Ualberta.ca</a> <br />

Katrine Mallan is a Technical Services Librarian at Jacobs University, Bremen, Germany.  She received a Bachelor's degree in Arts and a Master's degree in Library and Information Studies from McGill University, Montreal, Canada. She can be contacted at: <a href="mailto:k.mallan@jacobs-university.de">k.mallan@jacobs-university.de</a> </p> 
 

<form action="paper465.html"> 
<fieldset> 
<legend style="color: white; background-color: #5E96FD; font-size: medium; padding: .1ex .5ex; border-right: 1px solid navy; border-bottom: 1px solid navy; font-weight: bold;">References</legend> 

<ul> 
    <li id="boo00">Booth, A. (2000). <em>Librarian heal thyself: evidence-based librarianship, useful, practicable, desirable?</em>  Paper presented at the 8th International Congress on Medical Librarianship, 2nd-5th July 2000, London, UK.</li>

    <li id="boo03">Booth, A. &amp; Brice, A. (2003). Clear-cut? Facilitating health librarians to use information research in practice.  <em>Health Libraries Review</em>, <strong>20</strong>(1), 45-52.</li>

    <li id="boo04">Booth, A. &amp; Brice, A. (2004). Appraising the evidence. In A. Booth &amp; A. Brice, (Eds.), <em>Evidence-based practice for information professionals: a handbook</em> (pp. 104-118). London: Facet Publishing.</li>

    <li id="daw05">Dawes, M., Summerskill, W., Glasziou, P., Cartabellotta, A., Martin, J., Hopayian, K. <em>et al.</em> (2005). <a href="http://www.webcitation.org/5wZY38E9r">Sicily statement on evidence-based practice</a>. <em>BMC Medical Education</em>, <strong>5</strong>(1). Retrieved 17 February, 2011 from http://www.biomedcentral.com/1472-6920/5/1 (Archived by WebCite&reg; at http://www.webcitation.org/5wZY38E9r)</li>

    <li id="gly06">Glynn, L. (2006). A critical appraisal tool for library and information research. <em>Library Hi Tech</em>, <strong>24</strong>(3), 387-399.</li>

    <li id="gra08">Grad, R.M., Pluye, P., Mercer, J., Marlow, B., Beauchamp, M.E., Shulha, M. <em>et al.</em> (2008). Impact of research-based synopses delivered as daily e-mail: a prospective observational study. <em>Journal of the American Medical Informatics Association</em>, <strong>15</strong>(2), 240-245.</li>

    <li id="kou06">Koufogiannakis, D., Booth, A. &amp; Brettle, A. (2006). <a href="http://www.webcitation.org/5wZYHZWsM">ReLIANT: Reader&rsquo;s guide to the Literature on Interventions Addressing the Need for education and Training</a>. Retrieved 22 February, 2010 from http://eprints.rclis.org/7163/ content (Archived by WebCite&reg; at http://www.webcitation.org/5wZYHZWsM)</li>

    <li id="kou04">Koufogiannakis, D., Slater, L. &amp; Crumley, E. (2004). A content analysis of librarianship research. <em>Journal of Information Science</em>, <strong>30</strong>(3), 227-239.</li>

    <li id="rey00">Reynolds, S. (2000). The anatomy of evidence-based practice: principles and methods. In E. Trinder &amp; S. Reynolds, (Eds.), <em>Evidence-based practice: a critical appraisal</em> (pp. 17-34). Oxford: Blackwell Science.</li>

    <li id="zha09">Zhang, Y. &amp; Wildemuth, B.M. (2009). Qualitative analysis of content. In B.M. Wildemuth, (Ed.), <em>Applications of social research methods to questions in information and library science</em>, (pp. 308-319). Westport, CT: Libraries Unlimited.</li>
</ul>
</fieldset> 
</form> 
 
 
<form action="paper465.html"> 
<fieldset> 
<legend style="color: white; background-color: #5E96FD; font-size: medium; padding: .1ex .5ex; border-right: 1px solid navy; border-bottom: 1px solid navy; font-weight: bold;">How to cite this paper</legend> 
<div><br /> 
Kloda, L.A., Koufogiannakis, D. &amp; Mallan, K. (2011). &quot;Transferring evidence into practice: what evidence summaries of library and information studies research tell practitioners&quot; <em>Information Research</em>, <strong>16</strong>(1) paper 465. [Available at http://InformationR.net/ir/16-1/paper465.html]</div> 

</fieldset> 
</form> 
 

<table cellspacing="10" align="center"> 
	<tr> 
		<td colspan="3" align="center" style="background-color: #5E96FD; color: white; font-family: verdana; font-size: small; font-weight: bold;">Find other papers on this subject</td></tr> 
	<tr> 
		<td align="center" valign="top"> 
 
<form method="get" action="http://scholar.google.com/scholar" target="_blank"> 
			<table bgcolor="#ffffff"> 
				<tr> 
					<td nowrap="nowrap" valign="top" align="center" height="32"><input type="hidden" name="q" size="31" maxlength="255" value="&quot;evidence-based practice&quot; research (libraries OR librarians)"></input> <br /> 
<input type="submit" name="sa" value="Scholar Search"  style="font-size: small; font-family: Verdana; font-weight: bold;"></input> 
<input type="hidden" name="num" value="100"></input> 
					</td> 
				</tr> 
			</table> 
 

</form> 
		</td> 
		<td align="center" valign="top"> 
<!-- Search Google --> 
 
<form method="get" action="http://www.google.com/custom" target="_blank"> 
			<table bgcolor="#ffffff"> 
				<tr> 
					<td nowrap="nowrap" valign="top" align="center" height="32"><input type="hidden" name="q" size="31" maxlength="255" value="&quot;evidence-based practice&quot; research (libraries OR librarians)"></input><br /> 
<input type="submit" name="sa" value="Google Search" style="font-family: Verdana; font-weight: bold; font-size: small;"></input> 
<input type="hidden" name="client" value="pub-5081678983212084"></input> 
<input type="hidden" name="forid" value="1"></input> 
 
<input type="hidden" name="ie" value="ISO-8859-1"></input> 
<input type="hidden" name="oe" value="ISO-8859-1"></input> 
<input type="hidden" name="cof" value="GALT:#0066CC;GL:1;DIV:#999999;VLC:336633;AH:center;BGC:FFFFFF;LBGC:FF9900;ALC:0066CC;LC:0066CC;T:000000;GFNT:666666;GIMP:666666;FORID:1;"></input> 
<input type="hidden" name="hl" value="en"></input> 
					</td> 
				</tr> 
			</table> 

</form> 
</td> 
<td align="center" valign="top"> 
<form method="get" action="http://www.bing.com" target="_blank"> 
			<table bgcolor="#ffffff"> 
				<tr> 
 
					<td nowrap="nowrap" valign="top" align="center" height="32"><input type="hidden" name="q" size="31" maxlength="255" value="&quot;evidence-based practice&quot; research (libraries OR librarians)"></input> <br /> 
<input type="submit" name="sa" value="Bing"  style="font-size: small; font-family: Verdana; font-weight: bold;"></input> 
<input type="hidden" name="num" value="100"></input> 
					</td> 
				</tr> 
			</table> 
</form> 
 
		</td> 
	</tr> 
</table> 
 

<div align="center">Check for citations, <a href="http://scholar.google.co.uk/scholar?hl=en&amp;q=http://informationr.net/ir/16-1/paper465.html&amp;btnG=Search&amp;as_sdt=2000">using Google Scholar</a></div>
<br />
<div align="center"> 
<img src="http://images.del.icio.us/static/img/delicious.small.gif" alt="logo" /> <a href="http://del.icio.us/post" onclick="window.open('http://del.icio.us/post?v=4&amp;noui&amp;jump=close&amp;url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title), 'delicious', 'toolbar=no,width=700,height=400'); return false;">Bookmark This Page</a> 
</div> 
<hr size="1" style="color: #5E96FD;" /> 
 
<h2  id="appa">Appendix A: Guidelines for evidence summary writers</h2> 

<p>Evidence Summaries are brief critical appraisal reviews of current research articles. The summary follows a standardized format to ensure consistency and ease of use for readers. All evidence summaries will undergo peer-review to ensure quality. For each summary, the following components must be present:</p>

<p>1.	Descriptive title of the review, that is indicative of what we can learn from this research.</p>

<p>2.	Citation information for the article being reviewed. Use MLA format. </p>

<p>3.	Reviewer's name and contact information (this needs to be left out when submitting for peer review)</p>

<p>4.	Structured Abstract to include the following components:</p>

<ul><li>Objective - the objective of the study</li>

<li>Design - type of research study design used</li>

<li>Setting - environment in which the research took place; i.e., large public library in Canada, corporate information centre in the United States, small community college in Australia.</li>

<li>Subjects - the number and characteristics of the subjects that participated in the study; i.e.,: 75 senior citizens who were homebound.</li>

<li>Methods - a brief paragraph on the research methodology; i.e., students were randomized into two groups, with one receiving computer assisted instruction, the other receiving traditional lecture/demonstration. At the end of the term students were asked to complete a skills test.etc.</li>

<li>Main results - state the main outcome of the research study; i.e., e-books were favored by 2-1 over print books by young adults participating in the focus group.</li>

<li>Conclusion - state the conclusion and practice implications for this research study. i.e., based on the research results, signage in the library was improved and replaced. A follow-up study will be conducted to further examine impact of the change.</li>
</ul>


<p>5.	Commentary - provide 300-400 words of commentary on the quality of the research article. What was good about it; what are areas of concern; what could have been improved? Commentary should address the strength of the evidence presented, methodology used, issues of reliability, validity and applicability. What is the significance of the article to library and information practice; what are the practice implications for librarians in the target environment? Try to place this research article in the wider context of research available on this topic. How can this research be applied to everyday practice?  Reviewers should refer to a critical appraisal checklist to ensure all important elements of assessment have been taken into consideration.  </p>



<h2 id="appb">Appendix B: Data extraction form</h2>

<p>For elements of commentary, indicate, if the item is present in the commentary, if it is mentioned as a STRENGTH, or WEAKNESS of the original study, or if it is mentioned neutrally. If it is not present, leave the item blank.<br />
<br />
Highlight the corresponding segment(s) in the commentary, and use the code to identify these (e.g., v3, a0)<br />
<br />
* Required<br />
<br />
ID * (enter unique ID for Evidence Summary Commentary from document ) __________<br />
<br />
Name of coder _____________________________<br />
<br />
Title of Evidence Summary (cut and paste full title of Evidence Summary here)<br />
_________________________________________________________________________<br />
<br />
<br />
Research situated in a wider context the ES writer mentions other research specifically, or generally <br />
Yes, the ES writer situates the study in a wider context <br />
AND the ES writer names other researchers or other studies specifically <br />
<br />
VALIDITY (v1) focused issue/research question The ES writer discusses the issue/research question&#39;&#39;s focus <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
<br />
VALIDITY (v2) conflict data collection and service providers The ES writer addresses potential conflict of interest: those involved in the collection of data also delivering a service to the user group. <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
<br />
VALIDITY (v3) appropriate and replicable methods The ES writer addresses the research methods (appropriateness of methods and level of description) <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
<br />
VALIDITY (v4) appropriate population, representative sample The ES writer discusses the appropriateness of the population and sampling technique, and/or the level of description of the sampling/population <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
<br />
VALIDITY (v5) tested or piloted methods/instruments The ES writer discusses the data collection instruments&#39; validation, appropriateness, or usage <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
<br />
VALIDITY (v0) other validity, but does not fit well into existing categories (please explain / provide emerging category) __________________________________________________<br />
<br />
RELIABILITY (r1) results clearly explained The ES writer discusses the clarity of the results description/explanation of the original author <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
<br />
RELIABILITY (r2) response rate The ES writer discusses the original study&#39;s response rate (as a % or proportion) <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
The ES writer includes the number of respondents, but not as a % or proportion <br />
<br />
RELIABILITY (r3) analysis useful and easy to understand The ES writer discusss the usefulness of the analysis, and the presentation/organization (e.g., in table, with numbers rather than just %s) <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
<br />
RELIABILITY (r4) analysis appropriate and useful (stats or other) The ES writer discusses the appropriateness of the analysis method employed <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
<br />
RELIABILITY (r5) results address original research question The ES writer discusses whether or not the study&#39;s results address the original research question <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
<br />
RELIABILITY (r6) limitations The ES writer discusses the limitations of the study (even if restating limitations mentioned by the original author) <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
<br />
RELIABILITY (r7) conclusions based on results and supported by data The ES writer discusses to what extent the conclusion are based on the actual results of the study <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
<br />
RELIABILITY (r0) other reliability, but does fit well into existing categories (please explain / provide emerging category) ___________________________________________________<br />
<br />
APPLICABILITY (a1) implications for practice reported in original study The ES writer discusses the original author&#39;s statement(s) about implications for practice <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
<br />
APPLICABILITY (a2) to other populations The ES writer discusses the applicability of this resaerch to other populations beyond what was discussed by the original author <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
<br />
APPLICABILITY (a3) additional research needed The ES writer addresses additional local information required to move forward <br />
+ Appraised positively by ES writer (STRENGTH of original study) <br />
- Appraised negatively by ES writer (WEAKNESS of original study) <br />
~ Noted by ES writer (NEUTRAL or UNCLEAR appraisal) <br />
<br />
APPLICABILITY (a0) other applicability, but does fit well into existing categories (please explain / provide emerging category) ___________________________________________<br />
<br />
Overall siginificance of the original study The ES writer addresses the theoretical/overall significance of the research (not just practical implications), e.g., using words like &quot;important,&quot; &quot;contribution to the field,&quot; <br />
The ES writer includes a statement about the overall significance of the research study <br />
The ES writer includes future research are
OTHER emerging category in addition to context, validity, reliability, applicability, significance <br />
_____________________________________________________________________________<br />
<br />
Quotable segment(s)? indicate if there is a representative example of one or more of the above categories in the commentary <br />
(copy &amp; pastas or questions to consider <br />
<br />e here)<br />
<br />
Remarks by the coder ____________________________________________________________<br />
</p>


 <hr size="1" style="color: #5E96FD;" /> 
<table align="center" cellpadding="10"> 
<tr><td align="center" valign="top"><div>  <a href="http://www.digits.net" target="_blank">
    <img src="http://counter.digits.net/?counter={422736f9-762f-8cb4-4d2c-47680bc3a607}&amp;template=simple" 
     alt="Hit Counter by Digits" border="0"  />
  </a></div></td> 
 
<td align="center" valign="top"><div> 
&copy; the authors 2011. <br />Last updated: 28 February, 2011
</div></td> 
 
         <td align="center" valign="middle"><img src="../valid-xhtml10.gif" alt="Valid XHTML 1.0!" height="16" width="44" /><!--ONESTAT SCRIPTCODE START--> 
<!--
// Modification of this code is not allowed and will permanently disable your account!
// Account ID : 281971
// Website URL: http://InformationR.net/ir/
// Copyright (C) 2002-2006 OneStat.com All Rights Reserved
--> 
<div id="OneStatTag"><table border='0' cellpadding='0' cellspacing='0'><tr><td align='center'> 
<script type="text/javascript"> 
<!--
function OneStat_Pageview()
{
    var d=document;
    var sid="281971";
    var CONTENTSECTION="";
    var osp_URL=d.URL;
    var osp_Title=d.title;
    var t=new Date();
    var p="http"+(d.URL.indexOf('https:')==0?'s':'')+"://stat.onestat.com/stat.aspx?tagver=2&sid="+sid;
    p+="&url="+escape(osp_URL);
    p+="&ti="+escape(osp_Title);
    p+="&section="+escape(CONTENTSECTION);
    p+="&rf="+escape(parent==self?document.referrer:top.document.referrer);
    p+="&tz="+escape(t.getTimezoneOffset());
    p+="&ch="+escape(t.getHours());
    p+="&js=1";
    p+="&ul="+escape(navigator.appName=="Netscape"?navigator.language:navigator.userLanguage);
    if(typeof(screen)=="object"){
       p+="&sr="+screen.width+"x"+screen.height;p+="&cd="+screen.colorDepth;
       p+="&jo="+(navigator.javaEnabled()?"Yes":"No");
    }
    d.write('<a href="http://www.onestatfree.com/aspx/login.aspx?sid='+sid+'" target=_blank><img id="ONESTAT_TAG" border="0" src="'+p+'" alt="This site tracked by OneStatFree.com. Get your own free site tracker."></'+'a>');
}
 
OneStat_Pageview();
//--> 
</script> 
<noscript> 
<a href="http://www.onestatfree.com"><img border="0" src="http://stat.onestat.com/stat.aspx?tagver=2&amp;sid=281971&amp;js=No&amp;" alt="online Web site analytics" /></a> 
</noscript> 
</td></tr><tr><td align='center'><div style="COLOR:black;display:none;FONT-FAMILY:'Verdana';"><a href="http://www.onestat.com" style="text-decoration:none;">online Web site analytics</a><br /></div></td></tr></table></div> 
<!--ONESTAT SCRIPTCODE END--> 
</td></tr> 
</table> 

<hr size="3" style="color: #5E96FD;" /> 
 
<table align="center"><tr><td><div class="button"> 
 

<ul>
	<li><a href="infres161.html">Contents</a> | </li>
	<li><a href="http://www.informationr.net/ir//iraindex.html">Author index</a> | </li>
	<li><a href="../irsindex.html">Subject index</a> | </li>
	<li><a href="../search.html">Search</a> | </li>
	<li><a href="../index.html">Home</a></li>
</ul> 

</div></td></tr></table> 
 
 <hr size="3" style="color: #5E96FD;" /> 
<script src="http://www.google-analytics.com/urchin.js" type="text/javascript"> 
</script> 
<script type="text/javascript"> 
_uacct = "UA-672528-1";
urchinTracker();
</script> 
</body> 
</html> 
